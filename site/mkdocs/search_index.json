{
    "docs": [
        {
            "location": "/", 
            "text": "Select a document from the left or from the drop-down menu on mobile devices.\n\n\nSearch all of the SlamData documentation easily by typing in keywords in the search bar above or in the menu on mobile devices.\n\n\nDownload the helpful \nSQL\u00b2 cheat sheet\n for a quick reference document.\n\n\nVisit our \nSlamData User Forum\n to get your questions answered.\n\n\nCompanies may wish to visit our \ncommercial support and service offerings\n as well.", 
            "title": "Home"
        }, 
        {
            "location": "/administration-guide/", 
            "text": "Administration Guide - Community Edition\n\n\nThis Administration Guide can assist with installing and configuring SlamData.  For information on how to use SlamData from a user perspective see the \nSlamData User Guide\n\n\n\n\n \n\n\nPrerequisites\n\n\n\n\n2 GB available memory\n\n\n300 MB disk space\n\n\nCredentials to one or more databases\n\n\nLatest version of Chrome, Firefox, Safari or Internet Explorer\n\n\nJava 1.8 if using Linux \n(Java Runtime is included with OS X and Windows installers)\n\n\nWe recommend the latest version of \nSlamData Community Edition\n\n\n\n\n\n\n \n\n\nLimitations\n\n\n\n\nWhen using MongoDB, version 2.6 or newer is required\n\n\n\n\n\n\n \n\n\nInstalling SlamData\n\n\nSlamData may be installed on a workstation or a server.  Workstation installation is typically best for Administrator or Business Analyst work and only needs to run when something must be configured or changed.  Server installation is best for providing services for a larger group of users (or SaaS environment) and should remain running at all times for end user access.\n\n\nMac OS X\n\n\nSlamData has been tested and runs on OS X versions 10.10 and newer.  It may run on older versions but has not been tested and is not yet supported.\n\n\n\n\nDownload SlamData\n\n\nOpen the downloaded disk image (.dmg file)\n\n\nDouble-click the installer. You may need to adjust 'Security \n Privacy' settings to allow downloaded apps from Anywhere.\n\n\nComplete the installation setup program\n\n\n\n\nLinux\n\n\nSlamData has been tested and runs on Ubuntu version 14.04 and newer and CentOS verion 7 and newer.  It may run on different Linux distributions and versions but has not been tested and is not yet supported.\n\n\n\n\nDownload SlamData\n\n\nEnsure you have the \nJava 8 JRE or Java 8 JDK\n installed.\n\n\nMake the installer executable: \nchmod +x slamdata_unix_version.sh\n\n\nRun the installer, providing answers to the prompts:\n./slamdata_unix_version.sh\n\n\n\n\nWindows\n\n\nSlamData has been tested and runs on Windows 7 Desktop and newer and Windows Server 2008 and newer.  It may run on older versions but has not been tested and is not yet supported.\n\n\n\n\nDownload SlamData\n\n\nRun the installer\n\n\nComplete the installation setup program.\n\n\n\n\n\n\n \n\n\nLaunching SlamData\n\n\nSlamData is comprised of a frontend interface and a backend analytics engine.  Launching the SlamData application will start both.\n\n\nMac OS X\n\n\n\n\nOpen the Applications folder\n\n\nDouble-click on the SlamData icon\n\n\n\n\nA new browser window or tab will open displaying the SlamData interface. The SlamData icon will appear in the OS X dock. As with other dock applications the SlamData icon may be right-clicked and the application terminated.\n\n\nLinux\n\n\n\n\nChange directory to the location of the SlamData executable: \ncd SlamData-version\n\n\nExecute the SlamData executable:  \n./SlamData\n\n\n\n\nSome Linux systems may not launch a browser automatically. If this is the case, open a browser and point it to the following URL: \nhttp://localhost:20223/slamdata\n\n\nWindows\n\n\n\n\nOpen the Start menu\n\n\nClick on the newly installed SlamData icon or use the app search bar and type \nslamdata\n and press return to launch it. Select appropriate network security settings if prompted.\n\n\n\n\n\n\n \n\n\nConnecting to a Database\n\n\nConnecting to a database is the first step to analyzing data.  SlamData does not provide a database to connect to.  As more databases are supported by SlamData they will be listed below.\n\n\nMongoDB\n\n\nNote: \n\n\n\n\nOnly MongoDB versions 2.6 and newer are supported by SlamData.\n\n\n\n\nTo connect to MongoDB click on the Mount \n icon in the upper right.\n\n\nA mount dialog will be presented:\n\n\n\n\nEnter a name for the database mount.  This name is used in the SlamData UI as well as SQL\u00b2 query paths.  Use a name that makes sense for the environment.  For instance if this database were hosted on Amazon AWS/EC2 it might be named \naws\n or \naws-1\n.\n\n\nSelect \nMongoDB\n as the mount type.  Other mount types will be discussed later.  Once a Mount type is selected additional fields will appear in the dialog based on the mount type selected.\n\n\nUse the following table to assist in providing example values for the remaining fields:\n\n\n\n\n\n\n\n\nField\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nHost\n\n\ndb.example.com\n\n\n\n\n\n\nPort\n\n\n27017\n\n\n\n\n\n\nUsername\n\n\njoe\n\n\n\n\n\n\nPassword\n\n\n*******\n\n\n\n\n\n\nDatabase\n\n\njoesdb\n\n\n\n\n\n\nSettings\n\n\n\n\n\n\n\n\n\n\nAn example form might look like this:\n\n\n\n\nNote\n\n\n\n\nWhen using MongoDB the database field value should be the database the username and password will authenticate against. This value will depend on which database the user was created in; as such it could be \nadmin\n, the name of the user or something completely different.\n\n\n\n\nClick \nMount\n to mount the database in SlamData.\n\n\nSeveral Mounts\n\n\nAfter mounting several databases the SlamData UI might look like the following image.  In this image there are three separate mounts named \naws\n, \nkirk\n and \nmacbook\n, the last likely representing a locally mounted database.\n\n\n\n\nNote\n:\n\n\n\n\nKeep in mind that with \nSlamData Advanced\n you can limit which databases, collections and charts can be seen based on OAuth authentication and the SlamData authorization model.\n\n\n\n\n \n\n\nAdvanced Configuration\n\n\nConfiguration File\n\n\nThe SlamData configuration file allows an administrator to change settings such as the port number SlamData listens on, the mounts available and more.  The location of the configuration file depends upon the operating system being used.\n\n\n\n\n\n\n\n\nOperating System\n\n\nConfiguration File Location\n\n\n\n\n\n\n\n\n\n\nApple OS X\n\n\n$HOME/Library/Application Support/quasar/quasar-config.json\n\n\n\n\n\n\nMicrosoft Windows\n\n\n%HOMEDIR%\\AppData\\Local\\quasar\\quasar-config.json\n\n\n\n\n\n\nLinux (various vendors)\n\n\n$HOME/.config/quasar/quasar-config.json\n\n\n\n\n\n\n\n\nSlamData Advanced edition has an extended format of the configuration file which is not covered in this document. Please refer to the SlamData Advanced Administration Guide that you were given after purchase of the Advanced edition.\n\n\nAn example configuration file might appear like this:\n\n\n{\n  \nserver\n: {\n    \nport\n: 8080\n  },\n  \nmountings\n: {\n    \n/aws/\n: {\n      \nmongodb\n: {\n        \nconnectionUri\n: \nmongodb://myUser:myPass@aws-box.example.com:27017/admin\n\n      }\n    },\n    \n/kirk/\n: {\n      \nmongodb\n: {\n        \nconnectionUri\n: \nmongodb://myUser2:myPass@win-box.example.com:27017/admin?ssl=true\n\n      }\n    },\n    \n/macbook/\n: {\n      \nmongodb\n: {\n        \nconnectionUri\n: \nmongodb://localhost:27017\n\n      }\n    }\n  }\n}\n\n\n\n\nMount Options\n\n\nThe mount dialog will display the appropriate fields based on the mount type selected.  For each database type that SlamData supports a section below explains the options available.\n\n\nMongoDB\n\n\nFor MongoDB the values listed in the \nConnection Options\n on the MongoDB web site are supported. As of MongoDB 2.6 these options are listed below.\n\n\n\n\n\n\n\n\nOptions\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nssl\n\n\ntrue\n\n\nEnable SSL encryption\n\n\n\n\n\n\nconnectTimeoutMS\n\n\n15000\n\n\nThe time in milliseconds to attempt a connection before timing out\n\n\n\n\n\n\nsocketTimeoutMS\n\n\n10000\n\n\nThe time in milliseconds to attempt a send or receive on a socket before the attempt times out\n\n\n\n\n\n\n\n\nSQL\u00b2 View\n\n\nSQL\u00b2 Views are covered in detail in the SlamData Users Guide.\n\n\nOther Databases\n\n\nSupport for other relational and NoSQL databases is coming in 2016.\n\n\nEnabling SSL\n\n\nIf you have trouble following the steps below you may also view our \nSSL tutorial video\n.\n\n\nIf a database connection supports SSL encryption, which is to say encryption between a client and server such as SlamData and the database, additional configuration is necessary.\n\n\nThe backend engine of SlamData is written in \nScala\n and executes within a Java Virtual Machine (JVM).  To enable SSL encryption several options must be passed to the JVM when running SlamData.  SlamData simplifies this by allowing these options to be listed in a text file that the SlamData launcher will reference when executed.  The file location for each operating system is listed below:\n\n\n\n\n\n\n\n\nOperating System\n\n\nFile Location\n\n\n\n\n\n\n\n\n\n\nApple OS X\n\n\n/Applications/SlamData-version.app/Contents/vmoptions.txt\n\n\n\n\n\n\nMicrosoft Windows\n\n\nC:\\Programs Files (x86)\\slamdata-version\\SlamData.vmoptions\n\n\n\n\n\n\nLinux (various vendors)\n\n\n$HOME/slamdata-version/SlamData.vmoptions\n\n\n\n\n\n\n\n\nThere are four important options that must be passed to the JVM at startup to enable SSL. These options point the JVM to a Java Trust Store and a Java Key Store.  Adding certificates and keys to these files are not covered in this guide and it is assumed your security or network administrator has provided you with the appropriate information.\n\n\n\n\n\n\n\n\nJVM Optiosn\n\n\nPurpose\n\n\n\n\n\n\n\n\n\n\njavax.net.ssl.trustStore\n\n\nThe location of the encrypted trust store file\n\n\n\n\n\n\njavax.net.ssl.keyStore\n\n\nThe location of the encrypted key store file\n\n\n\n\n\n\njavax.net.ssl.trustStorePassword\n\n\nThe password required to decrypt the trust store file\n\n\n\n\n\n\njavax.net.ssl.keyStorePassword\n\n\nThe password required to decryp the key store file\n\n\n\n\n\n\n\n\nThe example contents of the file may look something like this:\n\n\n-Xms1g\n-Xmx4g\n-Djavax.net.ssl.trustStore=/Users/me/ssl/truststore.jks\n-Djavax.net.ssl.keyStore=/Users/me/ssl/keystore.jks\n-Djavax.net.ssl.trustStorePassword=mySecretPassword\n-Djavax.net.ssl.keyStorePassword=mySecretPassword\n\n\n\n\nThe first two lines specify that 1GB and 4GB of physical memory should be reserved as a minimum and maximum memory usage guideline, respectively.", 
            "title": "Administration Guide"
        }, 
        {
            "location": "/administration-guide/#administration-guide-community-edition", 
            "text": "This Administration Guide can assist with installing and configuring SlamData.  For information on how to use SlamData from a user perspective see the  SlamData User Guide", 
            "title": "Administration Guide - Community Edition"
        }, 
        {
            "location": "/administration-guide/#prerequisites", 
            "text": "2 GB available memory  300 MB disk space  Credentials to one or more databases  Latest version of Chrome, Firefox, Safari or Internet Explorer  Java 1.8 if using Linux  (Java Runtime is included with OS X and Windows installers)  We recommend the latest version of  SlamData Community Edition", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/administration-guide/#limitations", 
            "text": "When using MongoDB, version 2.6 or newer is required", 
            "title": "Limitations"
        }, 
        {
            "location": "/administration-guide/#installing-slamdata", 
            "text": "SlamData may be installed on a workstation or a server.  Workstation installation is typically best for Administrator or Business Analyst work and only needs to run when something must be configured or changed.  Server installation is best for providing services for a larger group of users (or SaaS environment) and should remain running at all times for end user access.", 
            "title": "Installing SlamData"
        }, 
        {
            "location": "/administration-guide/#mac-os-x", 
            "text": "SlamData has been tested and runs on OS X versions 10.10 and newer.  It may run on older versions but has not been tested and is not yet supported.   Download SlamData  Open the downloaded disk image (.dmg file)  Double-click the installer. You may need to adjust 'Security   Privacy' settings to allow downloaded apps from Anywhere.  Complete the installation setup program", 
            "title": "Mac OS X"
        }, 
        {
            "location": "/administration-guide/#linux", 
            "text": "SlamData has been tested and runs on Ubuntu version 14.04 and newer and CentOS verion 7 and newer.  It may run on different Linux distributions and versions but has not been tested and is not yet supported.   Download SlamData  Ensure you have the  Java 8 JRE or Java 8 JDK  installed.  Make the installer executable:  chmod +x slamdata_unix_version.sh  Run the installer, providing answers to the prompts: ./slamdata_unix_version.sh", 
            "title": "Linux"
        }, 
        {
            "location": "/administration-guide/#windows", 
            "text": "SlamData has been tested and runs on Windows 7 Desktop and newer and Windows Server 2008 and newer.  It may run on older versions but has not been tested and is not yet supported.   Download SlamData  Run the installer  Complete the installation setup program.", 
            "title": "Windows"
        }, 
        {
            "location": "/administration-guide/#launching-slamdata", 
            "text": "SlamData is comprised of a frontend interface and a backend analytics engine.  Launching the SlamData application will start both.", 
            "title": "Launching SlamData"
        }, 
        {
            "location": "/administration-guide/#mac-os-x_1", 
            "text": "Open the Applications folder  Double-click on the SlamData icon   A new browser window or tab will open displaying the SlamData interface. The SlamData icon will appear in the OS X dock. As with other dock applications the SlamData icon may be right-clicked and the application terminated.", 
            "title": "Mac OS X"
        }, 
        {
            "location": "/administration-guide/#linux_1", 
            "text": "Change directory to the location of the SlamData executable:  cd SlamData-version  Execute the SlamData executable:   ./SlamData   Some Linux systems may not launch a browser automatically. If this is the case, open a browser and point it to the following URL:  http://localhost:20223/slamdata", 
            "title": "Linux"
        }, 
        {
            "location": "/administration-guide/#windows_1", 
            "text": "Open the Start menu  Click on the newly installed SlamData icon or use the app search bar and type  slamdata  and press return to launch it. Select appropriate network security settings if prompted.", 
            "title": "Windows"
        }, 
        {
            "location": "/administration-guide/#connecting-to-a-database", 
            "text": "Connecting to a database is the first step to analyzing data.  SlamData does not provide a database to connect to.  As more databases are supported by SlamData they will be listed below.", 
            "title": "Connecting to a Database"
        }, 
        {
            "location": "/administration-guide/#mongodb", 
            "text": "Note:    Only MongoDB versions 2.6 and newer are supported by SlamData.   To connect to MongoDB click on the Mount   icon in the upper right.  A mount dialog will be presented:   Enter a name for the database mount.  This name is used in the SlamData UI as well as SQL\u00b2 query paths.  Use a name that makes sense for the environment.  For instance if this database were hosted on Amazon AWS/EC2 it might be named  aws  or  aws-1 .  Select  MongoDB  as the mount type.  Other mount types will be discussed later.  Once a Mount type is selected additional fields will appear in the dialog based on the mount type selected.  Use the following table to assist in providing example values for the remaining fields:     Field  Example      Host  db.example.com    Port  27017    Username  joe    Password  *******    Database  joesdb    Settings      An example form might look like this:   Note   When using MongoDB the database field value should be the database the username and password will authenticate against. This value will depend on which database the user was created in; as such it could be  admin , the name of the user or something completely different.   Click  Mount  to mount the database in SlamData.", 
            "title": "MongoDB"
        }, 
        {
            "location": "/administration-guide/#several-mounts", 
            "text": "After mounting several databases the SlamData UI might look like the following image.  In this image there are three separate mounts named  aws ,  kirk  and  macbook , the last likely representing a locally mounted database.   Note :   Keep in mind that with  SlamData Advanced  you can limit which databases, collections and charts can be seen based on OAuth authentication and the SlamData authorization model.", 
            "title": "Several Mounts"
        }, 
        {
            "location": "/administration-guide/#advanced-configuration", 
            "text": "", 
            "title": "Advanced Configuration"
        }, 
        {
            "location": "/administration-guide/#configuration-file", 
            "text": "The SlamData configuration file allows an administrator to change settings such as the port number SlamData listens on, the mounts available and more.  The location of the configuration file depends upon the operating system being used.     Operating System  Configuration File Location      Apple OS X  $HOME/Library/Application Support/quasar/quasar-config.json    Microsoft Windows  %HOMEDIR%\\AppData\\Local\\quasar\\quasar-config.json    Linux (various vendors)  $HOME/.config/quasar/quasar-config.json     SlamData Advanced edition has an extended format of the configuration file which is not covered in this document. Please refer to the SlamData Advanced Administration Guide that you were given after purchase of the Advanced edition.  An example configuration file might appear like this:  {\n   server : {\n     port : 8080\n  },\n   mountings : {\n     /aws/ : {\n       mongodb : {\n         connectionUri :  mongodb://myUser:myPass@aws-box.example.com:27017/admin \n      }\n    },\n     /kirk/ : {\n       mongodb : {\n         connectionUri :  mongodb://myUser2:myPass@win-box.example.com:27017/admin?ssl=true \n      }\n    },\n     /macbook/ : {\n       mongodb : {\n         connectionUri :  mongodb://localhost:27017 \n      }\n    }\n  }\n}", 
            "title": "Configuration File"
        }, 
        {
            "location": "/administration-guide/#mount-options", 
            "text": "The mount dialog will display the appropriate fields based on the mount type selected.  For each database type that SlamData supports a section below explains the options available.", 
            "title": "Mount Options"
        }, 
        {
            "location": "/administration-guide/#mongodb_1", 
            "text": "For MongoDB the values listed in the  Connection Options  on the MongoDB web site are supported. As of MongoDB 2.6 these options are listed below.     Options  Example  Description      ssl  true  Enable SSL encryption    connectTimeoutMS  15000  The time in milliseconds to attempt a connection before timing out    socketTimeoutMS  10000  The time in milliseconds to attempt a send or receive on a socket before the attempt times out", 
            "title": "MongoDB"
        }, 
        {
            "location": "/administration-guide/#sql2-view", 
            "text": "SQL\u00b2 Views are covered in detail in the SlamData Users Guide.", 
            "title": "SQL\u00b2 View"
        }, 
        {
            "location": "/administration-guide/#other-databases", 
            "text": "Support for other relational and NoSQL databases is coming in 2016.", 
            "title": "Other Databases"
        }, 
        {
            "location": "/administration-guide/#enabling-ssl", 
            "text": "If you have trouble following the steps below you may also view our  SSL tutorial video .  If a database connection supports SSL encryption, which is to say encryption between a client and server such as SlamData and the database, additional configuration is necessary.  The backend engine of SlamData is written in  Scala  and executes within a Java Virtual Machine (JVM).  To enable SSL encryption several options must be passed to the JVM when running SlamData.  SlamData simplifies this by allowing these options to be listed in a text file that the SlamData launcher will reference when executed.  The file location for each operating system is listed below:     Operating System  File Location      Apple OS X  /Applications/SlamData-version.app/Contents/vmoptions.txt    Microsoft Windows  C:\\Programs Files (x86)\\slamdata-version\\SlamData.vmoptions    Linux (various vendors)  $HOME/slamdata-version/SlamData.vmoptions     There are four important options that must be passed to the JVM at startup to enable SSL. These options point the JVM to a Java Trust Store and a Java Key Store.  Adding certificates and keys to these files are not covered in this guide and it is assumed your security or network administrator has provided you with the appropriate information.     JVM Optiosn  Purpose      javax.net.ssl.trustStore  The location of the encrypted trust store file    javax.net.ssl.keyStore  The location of the encrypted key store file    javax.net.ssl.trustStorePassword  The password required to decrypt the trust store file    javax.net.ssl.keyStorePassword  The password required to decryp the key store file     The example contents of the file may look something like this:  -Xms1g\n-Xmx4g\n-Djavax.net.ssl.trustStore=/Users/me/ssl/truststore.jks\n-Djavax.net.ssl.keyStore=/Users/me/ssl/keystore.jks\n-Djavax.net.ssl.trustStorePassword=mySecretPassword\n-Djavax.net.ssl.keyStorePassword=mySecretPassword  The first two lines specify that 1GB and 4GB of physical memory should be reserved as a minimum and maximum memory usage guideline, respectively.", 
            "title": "Enabling SSL"
        }, 
        {
            "location": "/users-guide/", 
            "text": "Users Guide\n\n\nIntroduction\n\n\nThis Users Guide can assist with daily usage of SlamData.  For information on how to install and configure SlamData see the \nSlamData Administration Guide\n\n\n\n\nLaunching SlamData\n\n\nStarting SlamData on a local system will automatically open a new browser window or tab with this URL: \nhttp://localhost:20223/slamdata/index.html\n\n\nIf SlamData is not installed locally but instead is on a remote system it can be accessed with a similar URL: \nhttp://servername:20223/slamdata/index.html\n where \nservername\n is the DNS name or IP address of the server.\n\n\n\n\n\n\nKey Concepts\n\n\nIt is useful to understand the following key concepts when using SlamData.\n\n\n\n\n\n\n\n\nFeature Name\n\n\nImage\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCluster\n\n\n\n\nA cluster represents a database server\n\n\n\n\n\n\nFolder\n\n\n\n\nA folder represents a database\n\n\n\n\n\n\nFile\n\n\n\n\nA file represents a table or collection\n\n\n\n\n\n\nNotebook\n\n\n\n\nA notebook contains a user's work\n\n\n\n\n\n\n\n\nA Cluster (server) may contain 0, 1 or more Folders (databases).\n\n\nA Folder (database) may contain 0, 1 or more Files (tables or collections).\n\n\nClicking on a Cluster, Folder, File or Notebook will display its contents.\n\n\n\n\nNotebooks\n\n\nNotebooks capture data workflows in a visual fashion that allows you to query data, transform and visualize it in the form of charts and reports.\n\n\nEach stage in a Notebook's workflow is called a \ncell\n or \ncard\n.  Cells can rely on data from previous cells or exist independent of other cells.\n\n\nA Notebook can be created in one of two ways:\n\n\n\n\nBy clicking on the Notebook \n icon in the upper right of the SlamData UI.\n\n\nClicking on a collection and renaming the subsequently displayed Notebook something other than \nUntitled Notebook\n.\n\n\n\n\nWhenever an existing Notebook is changed it is automatically saved and can be referred to in the future.  For instance if a Notebook contains an exploration cell followed by a query cell, the query can be changed and executed and the Notebook is then automatically saved.  This allows a user to work in a Notebook without fear of losing work or data.\n\n\n\n\n\n\nCell Types\n\n\nTo add a new cell to a Notebook click on the \n icon and select one of the following cell types\n\n\n\n\n\n\n\n\nCell Type\n\n\nImage\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nExploration\n\n\n\n\nBrowse data in a table or collection\n\n\n\n\n\n\nQuery\n\n\n\n\nLeverage SQL\u00b2 for powerful queries\n\n\n\n\n\n\nSearch\n\n\n\n\nSimple searching for non-technical users\n\n\n\n\n\n\nSlamDown\n\n\n\n\nCreate static or interactive forms\n\n\n\n\n\n\nAPI\n\n\n\n\nDevelopers pass values into queries for dynamic results\n\n\n\n\n\n\n\n\nExploration Cell\n\n\nAn example exploration cell is shown below.  Refer to the table below the image for the function of each icon surrounding the cell.\n\n\n\n\n\n\n\n\n\n\nIcon #\n\n\nPurpose\n\n\n\n\n\n\n\n\n\n\n1\n\n\nDownload the cell in CSV or JSON format\n\n\n\n\n\n\n2\n\n\nCreate a graphical chart based on this cell's data\n\n\n\n\n\n\n3\n\n\nSimple search on this cell's data\n\n\n\n\n\n\n4\n\n\nCreate a query on this cell's data\n\n\n\n\n\n\n5\n\n\nExecute or 'Play' the cell again\n\n\n\n\n\n\n6\n\n\nGo one level up or one level back\n\n\n\n\n\n\n7\n\n\nDouble click to rename this Notebook\n\n\n\n\n\n\n8\n\n\nHide the element which displays the path (useful when publishing Notebooks)\n\n\n\n\n\n\n9\n\n\nDelete this cell and all subsequent cells\n\n\n\n\n\n\n10\n\n\nDrop-down to select a different file path\n\n\n\n\n\n\n11\n\n\nRefresh the cell's data\n\n\n\n\n\n\n12\n\n\nGet HTML and JavaScript code to embed this cell in another web application\n\n\n\n\n\n\n13\n\n\nDisplays the schema of the collection or table being viewed\n\n\n\n\n\n\n\n\nBelow is an example of what a nested schema would look like within the exploration cell. In\nthis instance we have an array called \nprevious_addresses\n with several documents, each\ncontaining fields \ncity\n, \ncounty\n, \nlatitude\n, \nlongitude\n, \nstate\n and \nzip_code\n.\n\n\n\n\nThe corresponding JSON would appears like this in the database:\n\n\n...\n\nprevious_addresses\n: [\n    {\n      \ncity\n: \nNEW ORLEANS\n,\n      \nlongitude\n: -89.882564,\n      \ncounty\n: \nORLEANS\n,\n      \nstate\n: \nLA\n,\n      \nlatitude\n: 30.032997,\n      \nzip_code\n: 70157\n    },\n    {\n      \ncity\n: \nWEST ALTON\n,\n      \nlongitude\n: -90.403416,\n      \ncounty\n: \nSAINT CHARLES\n,\n      \nstate\n: \nMO\n,\n      \nlatitude\n: 38.83275,\n      \nzip_code\n: 63386\n    },\n    {\n      \ncity\n: \nOAKESDALE\n,\n      \nlongitude\n: -117.41146,\n      \ncounty\n: \nWHITMAN\n,\n      \nstate\n: \nWA\n,\n      \nlatitude\n: 47.079658,\n      \nzip_code\n: 99158\n    }\n...\n\n\n\n\n\n\nSlamDown Cell\n\n\nReports and forms are created with a subset of \nMarkdown\n called SlamDown.  SlamDown allows a relatively non-technical user to create interactive forms, charts and reports without understanding HTML or other complicated markup.\n\n\nFor specific syntax see the \nSlamDown Reference Guide\n and the \nCheat Sheet\n.\n\n\nBelow is an image of both a SlamDown cell and it's rendering directly following it.  As a reminder when you publish a Notebook you can include SlamDown cells, providing users with interactive forms that can directly affect a query and resulting report or chart.\n\n\n\n\n\n\nSearch Cell\n\n\nThe Search cell allows users to search through entire collections as well as previous search results resulting in a very refined data set.  In other words a user can use a search cell to refine results and then use another search cell to refine those results even further; this process can continue until the appropriate results are found.\n\n\nDefault Search\n\n\n\n\nCreate a new Search cell:\n\n\nClick on the Search \n icon on the left side of an existing exploration cell, or\n\n\nClick the Plus \n icon and then select the Search \n icon.\n\n\n\n\n\n\nIn the new Search cell, type in a search term and click the Play \n icon beneath it.\n\n\n\n\nIn the example image below notice the term \nUSA\n was searched for.  Also note that the field name was not specified.  By default \nSlamData will search all fields in all documents\n.  For very large collections and tables, especially those without proper indexes assigned, this could take some time to complete; however this also provides a very powerful feature to find data that exists but the location is unknown.\n\n\n\n\nField Specific Search\n\n\nTo limit a search to a specific field prefix the search term with the field name, for example:\n\n\ncountry:USA\n\n\n\n\nMultiple Field Values\n\n\nTo limit a search with multiple fields list them in the search field.  For example to find all women who won gold medals in a data set it may appear like this:\n\n\ngender:W  type:Gold\n\n\n\n\nMandatory Search\n\n\nTo search all documents that do \nnot\n contain a value the value should be prefixed with the (\n-\n) symbol as follows:\n\n\n-Skating\n\n\n\n\nNumeric Searches\n\n\nTo search on fields containing numeric values use the following examples.\n\n\nRange Search\n\n\nSearch for a field \nyear\n whose value is between \n1928\n and \n1932\n:\n\n\nyear:1928..1932\n\n\n\n\nNOT Range Search\n\n\nThe opposite of the previous example, this searches for field \nyear\n whose value is \nnot\n between \n1928\n and \n1932\n:\n\n\n-year:1928..1932\n\n\n\n\nComparison Search\n\n\nSearch for a field \nyear\n whose value is less than 1948.  Below we use the \n symbol for \nless than\n but the \n can also be used for \ngreater than\n:\n\n\nyear \n 1948\n\n\n\n\nStarts With Search\n\n\nSearch for a field \nname\n whose value starts with \nJen\n:\n\n\nname:Jen*\n\n\n\n\nNested Search\n\n\nSearch all documents which contain a \nfoo\n field which contains a \nbar\n field which contains the text \nbaz\n:\n\n\nfoo:bar:baz\n\n\n\n\nNote:\n\n\n\n\nA concise set of search examples can also be found in the \nSlamData CheatSheet\n\n\n\n\n\n\nQuery Cell\n\n\nThe Query cell allows users to utilize SQL\u00b2 to directly query one or more collections or tables.  This is the equivalent of a SQL command line console.\n\n\nTo create a query cell:\n\n\n\n\nFrom an empty Notebook click the Plus \n icon then click the Query \n icon\n\n\n\n\nOR\n\n\n\n\nFrom an existing cell click the Query \n icon to the left of the cell.\n\n\n\n\nIf the first option is selected the user will be presented with an empty Query cell.  If the second option is selected the user will be presented with a Query cell that contains a default query, highlighted with colored syntax as shown below:\n\n\n\n\nThe query can be manipulated in this alternate form but the highlighted text cannot be modified or removed.  If the user prefers more control the first option above may be preferred.  The Query cell also provides query completion at certain parts of your query as shown below:\n\n\n\n\nThe Query cell will also automatically highlight SQL\u00b2 keywords as shown the image above.  The query itself can be written on a single line (which will not word wrap) or on multiple lines.\n\n\nWhen a query is executed by clicking the Play \n icon the cell beneath the query cell will show a icon indicating the query is running.  When complete the query's results will display below the query.\n\n\nNote:\n\n\n\n\nIf a query takes longer than 30 seconds to execute SlamData considers it a timed out query and will result in an error.\n\n\n\n\nFor a complete review of SQL\u00b2 and example see the \nSQL\u00b2 Reference Guide\n.\n\n\n\n\nImporting Data\n\n\nSlamData allows users to import files in both \nJSON\n and \nCSV\n format.\n\n\nJSON files may be formatted either as multiple single documents or within a JSON array.\n\n\nNote:\n\n\n\n\nThe first line of CSV files will be used as a \nheader\n line creating the schema that the remaining rows will adhere to.\n\n\n\n\nTo upload a file into SlamData, follow these steps:\n\n\n\n\n\n\nNavigate to the database where the data should be imported.\n\n\n\n\n\n\nAt the top of the page click the Upload File \n icon.\n\n\n\n\n\n\nSelect a file from your file system.  Large files may take a few moments to upload.  After data has been imported a new collection will be created with the same name as the file.\n\n\n\n\n\n\nA new Untitled Notebook will be created that displays the new collection's data.\n\n\n\n\n\n\n\n\nExporting Data\n\n\nSlamData allows users to export refined result sets, collections and entire databases.\n\n\nResult Sets\n\n\nOnce a result set has been refined either through query cells or search cells it may then be downloaded in \nJSON\n or \nCSV\n formats.\n\n\n\n\n\n\nFrom an exploration cell or results set cell click the Download cell \n icon to the left of the cell.\n\n\n\n\n\n\nIn the newly created Download cell select either the CSV \n or JSON \n icon on the left.\n\n\n\n\n\n\nSelect the appropriate options in the cell.\n\n\n\n\n\n\nClick Download.\n\n\n\n\n\n\nSee the example image below of a query cell followed by the results cell.\n\n\n\n\nDownloading the data from this \nResults Cell\n provides the following JSON export file:\n\n\n[\n  {\n    \ngender\n: \nmale\n,\n    \nname\n: \nTory Escobar\n,\n    \naddresses\n: [\n      {\n        \ncity\n: \nOROFINO\n,\n        \nlongitude\n: -116.184848,\n        \ncounty\n: \nCLEARWATER\n,\n        \nstate\n: \nID\n,\n        \nlatitude\n: 46.4976,\n        \nzip_code\n: 83544\n      },\n      {\n        \ncity\n: \nARRIBA\n,\n        \nlongitude\n: -103.323143,\n        \ncounty\n: \nLINCOLN\n,\n        \nstate\n: \nCO\n,\n        \nlatitude\n: 39.316461,\n        \nzip_code\n: 80804\n      },\n      {\n        \ncity\n: \nOLGA\n,\n        \nlongitude\n: -122.983742,\n        \ncounty\n: \nSAN JUAN\n,\n        \nstate\n: \nWA\n,\n        \nlatitude\n: 48.557824,\n        \nzip_code\n: 98279\n      },\n      {\n        \ncity\n: \nDELRAY BEACH\n,\n        \nlongitude\n: -80.13473,\n        \ncounty\n: \nPALM BEACH\n,\n        \nstate\n: \nFL\n,\n        \nlatitude\n: 26.454218,\n        \nzip_code\n: 33484\n      },\n      {\n        \ncity\n: \nLYONS\n,\n        \nlongitude\n: -122.594993,\n        \ncounty\n: \nLINN\n,\n        \nstate\n: \nOR\n,\n        \nlatitude\n: 44.749921,\n        \nzip_code\n: 97358\n      }\n    ]\n  },\n  {\n    \ngender\n: \nfemale\n,\n    \nname\n: \nDamaris Savage\n,\n    \naddresses\n: [\n      {\n        \ncity\n: \nCROSSROADS\n,\n        \nlongitude\n: -103.209405,\n        \ncounty\n: \nLEA\n,\n        \nstate\n: \nNM\n,\n        \nlatitude\n: 32.690034,\n        \nzip_code\n: 88114\n      }\n    ]\n  },\n  {\n    \ngender\n: \nfemale\n,\n    \nname\n: \nSee Harrison\n,\n    \naddresses\n: []\n  }\n]\n\n\n\n\n\nCollections and Tables\n\n\nCollections and tables can also be exported in their entirety.  When browsing a folder (database) within the SlamData UI simply hover over the file (table or collection) and notice the icons that appear to the right.  Click on the Download \n icon.  See the image below with the highlighted icon.\n\n\n\n\nDatabases\n\n\nDatabases can be exported in their entirety as well.  Simply ensure the appropriate database and its underlying collections are displayed in the UI and click on the Download \n icon in the \ntop menu bar\n as shown in the image below.  A dialog will appear providing several options for the download and will result in a compress zip file containing all of the database's collections as separate files.", 
            "title": "Users Guide"
        }, 
        {
            "location": "/users-guide/#users-guide", 
            "text": "", 
            "title": "Users Guide"
        }, 
        {
            "location": "/users-guide/#introduction", 
            "text": "This Users Guide can assist with daily usage of SlamData.  For information on how to install and configure SlamData see the  SlamData Administration Guide", 
            "title": "Introduction"
        }, 
        {
            "location": "/users-guide/#launching-slamdata", 
            "text": "Starting SlamData on a local system will automatically open a new browser window or tab with this URL:  http://localhost:20223/slamdata/index.html  If SlamData is not installed locally but instead is on a remote system it can be accessed with a similar URL:  http://servername:20223/slamdata/index.html  where  servername  is the DNS name or IP address of the server.", 
            "title": "Launching SlamData"
        }, 
        {
            "location": "/users-guide/#key-concepts", 
            "text": "It is useful to understand the following key concepts when using SlamData.     Feature Name  Image  Description      Cluster   A cluster represents a database server    Folder   A folder represents a database    File   A file represents a table or collection    Notebook   A notebook contains a user's work     A Cluster (server) may contain 0, 1 or more Folders (databases).  A Folder (database) may contain 0, 1 or more Files (tables or collections).  Clicking on a Cluster, Folder, File or Notebook will display its contents.", 
            "title": "Key Concepts"
        }, 
        {
            "location": "/users-guide/#notebooks", 
            "text": "Notebooks capture data workflows in a visual fashion that allows you to query data, transform and visualize it in the form of charts and reports.  Each stage in a Notebook's workflow is called a  cell  or  card .  Cells can rely on data from previous cells or exist independent of other cells.  A Notebook can be created in one of two ways:   By clicking on the Notebook   icon in the upper right of the SlamData UI.  Clicking on a collection and renaming the subsequently displayed Notebook something other than  Untitled Notebook .   Whenever an existing Notebook is changed it is automatically saved and can be referred to in the future.  For instance if a Notebook contains an exploration cell followed by a query cell, the query can be changed and executed and the Notebook is then automatically saved.  This allows a user to work in a Notebook without fear of losing work or data.", 
            "title": "Notebooks"
        }, 
        {
            "location": "/users-guide/#cell-types", 
            "text": "To add a new cell to a Notebook click on the   icon and select one of the following cell types     Cell Type  Image  Description      Exploration   Browse data in a table or collection    Query   Leverage SQL\u00b2 for powerful queries    Search   Simple searching for non-technical users    SlamDown   Create static or interactive forms    API   Developers pass values into queries for dynamic results", 
            "title": "Cell Types"
        }, 
        {
            "location": "/users-guide/#exploration-cell", 
            "text": "An example exploration cell is shown below.  Refer to the table below the image for the function of each icon surrounding the cell.      Icon #  Purpose      1  Download the cell in CSV or JSON format    2  Create a graphical chart based on this cell's data    3  Simple search on this cell's data    4  Create a query on this cell's data    5  Execute or 'Play' the cell again    6  Go one level up or one level back    7  Double click to rename this Notebook    8  Hide the element which displays the path (useful when publishing Notebooks)    9  Delete this cell and all subsequent cells    10  Drop-down to select a different file path    11  Refresh the cell's data    12  Get HTML and JavaScript code to embed this cell in another web application    13  Displays the schema of the collection or table being viewed     Below is an example of what a nested schema would look like within the exploration cell. In\nthis instance we have an array called  previous_addresses  with several documents, each\ncontaining fields  city ,  county ,  latitude ,  longitude ,  state  and  zip_code .   The corresponding JSON would appears like this in the database:  ... previous_addresses : [\n    {\n       city :  NEW ORLEANS ,\n       longitude : -89.882564,\n       county :  ORLEANS ,\n       state :  LA ,\n       latitude : 30.032997,\n       zip_code : 70157\n    },\n    {\n       city :  WEST ALTON ,\n       longitude : -90.403416,\n       county :  SAINT CHARLES ,\n       state :  MO ,\n       latitude : 38.83275,\n       zip_code : 63386\n    },\n    {\n       city :  OAKESDALE ,\n       longitude : -117.41146,\n       county :  WHITMAN ,\n       state :  WA ,\n       latitude : 47.079658,\n       zip_code : 99158\n    }\n...", 
            "title": "Exploration Cell"
        }, 
        {
            "location": "/users-guide/#slamdown-cell", 
            "text": "Reports and forms are created with a subset of  Markdown  called SlamDown.  SlamDown allows a relatively non-technical user to create interactive forms, charts and reports without understanding HTML or other complicated markup.  For specific syntax see the  SlamDown Reference Guide  and the  Cheat Sheet .  Below is an image of both a SlamDown cell and it's rendering directly following it.  As a reminder when you publish a Notebook you can include SlamDown cells, providing users with interactive forms that can directly affect a query and resulting report or chart.", 
            "title": "SlamDown Cell"
        }, 
        {
            "location": "/users-guide/#search-cell", 
            "text": "The Search cell allows users to search through entire collections as well as previous search results resulting in a very refined data set.  In other words a user can use a search cell to refine results and then use another search cell to refine those results even further; this process can continue until the appropriate results are found.", 
            "title": "Search Cell"
        }, 
        {
            "location": "/users-guide/#default-search", 
            "text": "Create a new Search cell:  Click on the Search   icon on the left side of an existing exploration cell, or  Click the Plus   icon and then select the Search   icon.    In the new Search cell, type in a search term and click the Play   icon beneath it.   In the example image below notice the term  USA  was searched for.  Also note that the field name was not specified.  By default  SlamData will search all fields in all documents .  For very large collections and tables, especially those without proper indexes assigned, this could take some time to complete; however this also provides a very powerful feature to find data that exists but the location is unknown.", 
            "title": "Default Search"
        }, 
        {
            "location": "/users-guide/#field-specific-search", 
            "text": "To limit a search to a specific field prefix the search term with the field name, for example:  country:USA", 
            "title": "Field Specific Search"
        }, 
        {
            "location": "/users-guide/#multiple-field-values", 
            "text": "To limit a search with multiple fields list them in the search field.  For example to find all women who won gold medals in a data set it may appear like this:  gender:W  type:Gold", 
            "title": "Multiple Field Values"
        }, 
        {
            "location": "/users-guide/#mandatory-search", 
            "text": "To search all documents that do  not  contain a value the value should be prefixed with the ( - ) symbol as follows:  -Skating", 
            "title": "Mandatory Search"
        }, 
        {
            "location": "/users-guide/#numeric-searches", 
            "text": "To search on fields containing numeric values use the following examples.", 
            "title": "Numeric Searches"
        }, 
        {
            "location": "/users-guide/#range-search", 
            "text": "Search for a field  year  whose value is between  1928  and  1932 :  year:1928..1932", 
            "title": "Range Search"
        }, 
        {
            "location": "/users-guide/#not-range-search", 
            "text": "The opposite of the previous example, this searches for field  year  whose value is  not  between  1928  and  1932 :  -year:1928..1932", 
            "title": "NOT Range Search"
        }, 
        {
            "location": "/users-guide/#comparison-search", 
            "text": "Search for a field  year  whose value is less than 1948.  Below we use the   symbol for  less than  but the   can also be used for  greater than :  year   1948", 
            "title": "Comparison Search"
        }, 
        {
            "location": "/users-guide/#starts-with-search", 
            "text": "Search for a field  name  whose value starts with  Jen :  name:Jen*", 
            "title": "Starts With Search"
        }, 
        {
            "location": "/users-guide/#nested-search", 
            "text": "Search all documents which contain a  foo  field which contains a  bar  field which contains the text  baz :  foo:bar:baz  Note:   A concise set of search examples can also be found in the  SlamData CheatSheet", 
            "title": "Nested Search"
        }, 
        {
            "location": "/users-guide/#query-cell", 
            "text": "The Query cell allows users to utilize SQL\u00b2 to directly query one or more collections or tables.  This is the equivalent of a SQL command line console.  To create a query cell:   From an empty Notebook click the Plus   icon then click the Query   icon   OR   From an existing cell click the Query   icon to the left of the cell.   If the first option is selected the user will be presented with an empty Query cell.  If the second option is selected the user will be presented with a Query cell that contains a default query, highlighted with colored syntax as shown below:   The query can be manipulated in this alternate form but the highlighted text cannot be modified or removed.  If the user prefers more control the first option above may be preferred.  The Query cell also provides query completion at certain parts of your query as shown below:   The Query cell will also automatically highlight SQL\u00b2 keywords as shown the image above.  The query itself can be written on a single line (which will not word wrap) or on multiple lines.  When a query is executed by clicking the Play   icon the cell beneath the query cell will show a icon indicating the query is running.  When complete the query's results will display below the query.  Note:   If a query takes longer than 30 seconds to execute SlamData considers it a timed out query and will result in an error.   For a complete review of SQL\u00b2 and example see the  SQL\u00b2 Reference Guide .", 
            "title": "Query Cell"
        }, 
        {
            "location": "/users-guide/#importing-data", 
            "text": "SlamData allows users to import files in both  JSON  and  CSV  format.  JSON files may be formatted either as multiple single documents or within a JSON array.  Note:   The first line of CSV files will be used as a  header  line creating the schema that the remaining rows will adhere to.   To upload a file into SlamData, follow these steps:    Navigate to the database where the data should be imported.    At the top of the page click the Upload File   icon.    Select a file from your file system.  Large files may take a few moments to upload.  After data has been imported a new collection will be created with the same name as the file.    A new Untitled Notebook will be created that displays the new collection's data.", 
            "title": "Importing Data"
        }, 
        {
            "location": "/users-guide/#exporting-data", 
            "text": "SlamData allows users to export refined result sets, collections and entire databases.", 
            "title": "Exporting Data"
        }, 
        {
            "location": "/users-guide/#result-sets", 
            "text": "Once a result set has been refined either through query cells or search cells it may then be downloaded in  JSON  or  CSV  formats.    From an exploration cell or results set cell click the Download cell   icon to the left of the cell.    In the newly created Download cell select either the CSV   or JSON   icon on the left.    Select the appropriate options in the cell.    Click Download.    See the example image below of a query cell followed by the results cell.   Downloading the data from this  Results Cell  provides the following JSON export file:  [\n  {\n     gender :  male ,\n     name :  Tory Escobar ,\n     addresses : [\n      {\n         city :  OROFINO ,\n         longitude : -116.184848,\n         county :  CLEARWATER ,\n         state :  ID ,\n         latitude : 46.4976,\n         zip_code : 83544\n      },\n      {\n         city :  ARRIBA ,\n         longitude : -103.323143,\n         county :  LINCOLN ,\n         state :  CO ,\n         latitude : 39.316461,\n         zip_code : 80804\n      },\n      {\n         city :  OLGA ,\n         longitude : -122.983742,\n         county :  SAN JUAN ,\n         state :  WA ,\n         latitude : 48.557824,\n         zip_code : 98279\n      },\n      {\n         city :  DELRAY BEACH ,\n         longitude : -80.13473,\n         county :  PALM BEACH ,\n         state :  FL ,\n         latitude : 26.454218,\n         zip_code : 33484\n      },\n      {\n         city :  LYONS ,\n         longitude : -122.594993,\n         county :  LINN ,\n         state :  OR ,\n         latitude : 44.749921,\n         zip_code : 97358\n      }\n    ]\n  },\n  {\n     gender :  female ,\n     name :  Damaris Savage ,\n     addresses : [\n      {\n         city :  CROSSROADS ,\n         longitude : -103.209405,\n         county :  LEA ,\n         state :  NM ,\n         latitude : 32.690034,\n         zip_code : 88114\n      }\n    ]\n  },\n  {\n     gender :  female ,\n     name :  See Harrison ,\n     addresses : []\n  }\n]", 
            "title": "Result Sets"
        }, 
        {
            "location": "/users-guide/#collections-and-tables", 
            "text": "Collections and tables can also be exported in their entirety.  When browsing a folder (database) within the SlamData UI simply hover over the file (table or collection) and notice the icons that appear to the right.  Click on the Download   icon.  See the image below with the highlighted icon.", 
            "title": "Collections and Tables"
        }, 
        {
            "location": "/users-guide/#databases", 
            "text": "Databases can be exported in their entirety as well.  Simply ensure the appropriate database and its underlying collections are displayed in the UI and click on the Download   icon in the  top menu bar  as shown in the image below.  A dialog will appear providing several options for the download and will result in a compress zip file containing all of the database's collections as separate files.", 
            "title": "Databases"
        }, 
        {
            "location": "/securing-slamdata/", 
            "text": "Securing SlamData Community Edition\n\n\n\n\nIntroduction\n\n\nThis guide can assist with configuring NGINX (or other proxy service) and SlamData to limit access based on HTTP authentication and URL paths.\n\n\nNote:\n\n\n\n\nSlamData Advanced includes LDAP/OAuth authentication, fine grained authorization and user auditing - all of the security you need for peace of mind in the enterprise.\n\n\n\n\n\n\nSlamData is an all-in-one NoSQL visual analytics system.  You can get started right away by simply downloading the software and running it on your local system, or install it on a dedicated server.  There is no need to follow this guide if you do not need to limit access to SlamData.  If you need to restrict access to the SlamData application to certain users, then read on!\n\n\nWatching our YouTube \nvideo\n (~24 minutes) may help as well. The video is based off the instructions in this guide.\n\n\nThere are several methods of restricting access to SlamData.  This Quick Guide focuses on configuring SlamData to run under Nginx providing basic http authorization, then forwarding requests to the backend either on the same host or a separate host.\n\n\nThis quick guide does not give detailed instructions on how to setup firewall rules or configure applications other than SlamData and Nginx.\n\n\n\n\n\n\nAssumptions\n\n\nFor the example in this quick guide, we'll continue with the following\nassumptions:\n\n\n\n\n192.168.138.220: IP address of MongoDB host, already running on port 27017\n\n\n192.168.138.210: IP address of Backend host\n\n\n192.168.138.200: IP address of Nginx/SlamData UI host\n\n\nIf network security policy dictates, then network communication between hosts is\n  restricted via ipchains or other firewall mechanism.  This allows\n  simpler Backend and Nginx configuration files.\n\n\nThe reader has at least a basic understanding of JSON formatting and the Linux OS\n\n\nRunning on Ubuntu 14.04 or similar.  If using RedHat, use 'yum' rather than 'apt-get' for software management.\n\n\nYou have version 2.2.1 or newer of SlamData source code.\n\n\n\n\nIf your IP addresses differ, change as appropriate.\n\n\n\n\n\n\nArchitecture Overview\n\n\n\n\nAs can be noted from the above diagram, the network communications path is straight forward:\n\n\n\n\n\n\nA request comes into SlamData running under Nginx.\n\n\n\n\n\n\nNginx authenticates the user via standard http auth.\n\n\n\n\n\n\nAfter appropriate authentication, Nginx allows the user into the SlamData application, which communicates directly to the Backend's web API.\n\n\n\n\n\n\nThe backend runs the appropriate tasks on the data source, MongoDB in this case, and returns the results back upstream, through Nginx to the client.\n\n\n\n\n\n\nFor increased security, this configuration assumes the reader has setup appropriate network or OS-level restrictions that will deny access to requests other than the system upstream from it.  For instance, the MongoDB server should only allow requests to port 27017 from IP 192.168.138.210 (the Backend host).  Similarly, the Backend should only allow requests to port 8080 from IP 192.168.138.200 (the SlamData / Nginx host).  This setup is not covered in this guide and is left to the reader to implement.\n\n\n\n\n\n\nSetting Up The Backend\n\n\nThe first step is to download the Backend and build the source on the system that will\nbe hosting it.\n\n\n\n\nDownload and Build the Backend\n\n\n$ git clone https://github.com/slamdata/quasar\n$ cd quasar\n$ ./sbt test\n$ ./sbt 'project web' oneJar\n$ ./sbt 'project core' oneJar\n\n\n\nThese commands will download the latest source code, run the test suite,\nand build both the Web and Core projects jar files.\n\n\n\n\nConfigure\n\n\nConfigure the Backend server to connect to MongoDB.  Assuming there is a MongoDB\ndatabased called 'testdb' running on 192.168.138.220, your configuration file may\nbe called quasar-config.json and look like this:\n\n\n{\n  \"mountings\": {\n      \"/local\": {\n          \"mongodb\": {\n              \"connectionUri\": \"mongodb://192.168.138.220/testdb\"\n          }\n      }\n  },\n  \"server\": { \"port\": 8080 }\n}\n\n\n\nFor further details on the format of the configuration file, please see the\nBackend \nConfiguration\n documentation.\n\n\n\n\nTesting the Backend\n\n\n\n\nStart the Core jar file\n\n\nFrom the Backend server, run the core jar file to verify you have connectivity and your mounting is correct:\n\n\njava -jar ~/quasar/core/target/scala-2.11/core_2.11-2.2.1-SNAPSHOT-one-jar.jar ~/quasar-config.json\n\n\n\nOnce launched, a \nREPL\n console will appear representing a virtual file system where each MongoDB database is a directory, and each database directory contains one or more MongoDB collections.\n\n\nNotice how the the OS-like file system commands and SQL commands are executed directly after the $ prompt:\n\n\n\ud83d\udcaa $ ls\nlocal@\n\ud83d\udcaa $ cd local\n\ud83d\udcaa $ ls\nlocal/\ntestdb/\n\ud83d\udcaa $ cd testdb\n\ud83d\udcaa $ ls\ncoll1\n\ud83d\udcaa $ select * from coll1;\nMongo\ndb.coll1.find();\n\n\nQuery time: 0.0s\n name    | age   | gender  | minor  |\n---------|-------|---------|--------|\n Johnny  |  42.0 | male    |  false |\n Jenny   |  27.0 | female  |  false |\n Deb     |  33.0 | female  |  false |\n Billy   |  15.0 | male    |   true |\n\n\n\n\n\n\nStart the Web jar file\n\n\nOnce you have verified proper connectivity between the Backend and MongoDB, stop the Core jar file and now start the Web jar file with a slightly different syntax to point to the configuration file:\n\n\njava -jar ~/quasar/web/target/scala-2.11/web_2.11-2.2.1-SNAPSHOT-one-jar.jar -c ~/quasar-config.json\n\n\n\n\nCongratulations!  You now have two of the three necessary systems up and running for this configuration.\n\n\n\n\nInstall Pre-requisites\n\n\nYou should now be working on the system that will be hosting Nginx and SlamData. If you do not already have npm or node installed there, do so first.\n\n\nOn Linux:\n\n\n$ sudo apt-get install npm\n$ sudo apt-get install nodejs-legacy\n\n\n\nOn Mac:\n\n\n$ brew install npm\n$ brew install nodejs\n\n\n\nOnce npm is installed, utilize it to install \nBower\n,\n\nGulp\n and \nPureScript\n:\n\n\n$ npm install bower -g\n$ npm install gulp -g\n$ npm install purescript -g\n\n\n\n\n\nDownload and Build SlamData\n\n\nNow that npm, node, bower, gulp and PureScript are installed, download the SlamData source and compile:\n\n\n$ git clone https://github.com/slamdata/slamdata\n$ cd slamdata\n$ bower install\n$ npm install\n$ gulp\n\n\n\nWhen gulp completes, you should have a full application under the 'public' directory:\n\n\n[/Users/me/slamdata]$ ls public\ncss           fonts         img           index.html    js            notebook.html\n\n\n\n\nIt may be safest to copy this directory and place it under a directory with separate permissions for a more secure environment.  Whatever directory you use will be considered your web root directory in future steps.\n\n\n\n\n\n\nInstalling Nginx\n\n\nOS X\n\n\nOn OS X systems, consider using \nHomeBrew\n to install Nginx:\n\n\n$ brew install nginx\n\n\n\nRedhat / CentOS\n\n\nOn RedHat or CentOS systems:\n\n\n$ sudo yum install nginx\n\n\n\nUbuntu / Debian\n\n\nOn Ubuntu or Debian systems:\n\n\n$ sudo apt-get install nginx\n\n\n\n\n\nConfiguring Nginx\n\n\nThere are two main reasons we'll modify the Nginx configuration file in this guide:\n\n\n\n\n\n\nTo force user authentication, thus restricting access to known individuals\n\n\n\n\n\n\nTo redirect queries to the Backend engine on another host, thus limiting the\n   access path to the Backend API to individuals authenticated with Nginx.\n\n\n\n\n\n\nThis example will use the 'default' Nginx site configuration. Nginx has many configuration files and is a versatile tool, please contact your Nginx application administrator if you have questions, or visit the Nginx web site.\n\n\nIf Nginx is already running, stop it:\n\n\nsudo service nginx stop\n\n\n\n\n\nSetting up Authentication\n\n\nTo allow http authentication, we'll need to create a file which stores the names and passwords of allowed individuals.  To do this, use the apache2-utils package which provides those tools:\n\n\nsudo apt-get install apache2-utils\n\n\n\nNow create the htpasswd file we'll use to store the encrypted data:\n\n\nsudo htpasswd -c /etc/nginx/.htpasswd exampleuser\n\n\n\nReplace 'exampleuser' with a real username.  You'll then be prompted for a password and verification password.\n\n\nThis creates the file /etc/nginx/.htpasswd which we will reference in the Nginx configuration file below.\n\n\n\n\nNginx Configuration File\n\n\nAssuming the Nginx site configuration file is located at /etc/nginx/sites-available/default, replace the contents with the following code, making adjustments where necessary of course:\n\n\nserver {\n  listen 80 default_server;\n  listen [::]:80 default_server ipv6only=on;\n\n  server_name your_server_name;\n\n  client_max_body_size 1024M;\n\n  location / {\n    auth_basic \"Restricted\";\n    auth_basic_user_file /etc/nginx/.htpasswd;\n    root /slamdata/public;\n    try_files $uri $uri/ @backend;\n  }\n\n  location @backend {\n    proxy_set_header X-Forwarder-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_pass http://192.168.138.210:8080;\n  }\n}\n\n\n\nPay close attention to the 'root' directive above.  Replace the value with the web root directory referenced earlier. The configuration above ensures the following important actions:\n\n\n\n\n\n\nNginx runs on port 80\n\n\n\n\n\n\nEnables http authentication (lines beginning with 'auth_basic')\n\n\n\n\n\n\nNginx acts as a reverse proxy to the Backend service. This can either be\n   on a remote host (as indicated above) or your the same host as Nginx.\n\n\n\n\n\n\nSave the configuration and start or restart Nginx:\n\n\nsudo service nginx restart\n\n\n\nIf your network firewall is setup properly, the Backend should be shielded from all requests except those coming directly from the Nginx host.  Additionally all requests coming from the Nginx host should only originate from authenticated users via http authentication. You may test the SlamData / Nginx HTTP authorization by going to the URL:\n\n\nhttp://192.168.138.200\n\n\nYou should be immediately prompted for a username and password.  Upon successful authorization you should see the SlamData UI:\n\n\n\n\nNote that you are sending requests to Nginx (IP .200), which authenticates a username and then sends the request to the Backend (IP .210), then returns the results directly to\nthe browser.  The browser itself is not redirected as that would defeat the purpose of securing with Nginx.", 
            "title": "Securing SlamData"
        }, 
        {
            "location": "/securing-slamdata/#securing-slamdata-community-edition", 
            "text": "", 
            "title": "Securing SlamData Community Edition"
        }, 
        {
            "location": "/securing-slamdata/#introduction", 
            "text": "This guide can assist with configuring NGINX (or other proxy service) and SlamData to limit access based on HTTP authentication and URL paths.  Note:   SlamData Advanced includes LDAP/OAuth authentication, fine grained authorization and user auditing - all of the security you need for peace of mind in the enterprise.    SlamData is an all-in-one NoSQL visual analytics system.  You can get started right away by simply downloading the software and running it on your local system, or install it on a dedicated server.  There is no need to follow this guide if you do not need to limit access to SlamData.  If you need to restrict access to the SlamData application to certain users, then read on!  Watching our YouTube  video  (~24 minutes) may help as well. The video is based off the instructions in this guide.  There are several methods of restricting access to SlamData.  This Quick Guide focuses on configuring SlamData to run under Nginx providing basic http authorization, then forwarding requests to the backend either on the same host or a separate host.  This quick guide does not give detailed instructions on how to setup firewall rules or configure applications other than SlamData and Nginx.", 
            "title": "Introduction"
        }, 
        {
            "location": "/securing-slamdata/#assumptions", 
            "text": "For the example in this quick guide, we'll continue with the following\nassumptions:   192.168.138.220: IP address of MongoDB host, already running on port 27017  192.168.138.210: IP address of Backend host  192.168.138.200: IP address of Nginx/SlamData UI host  If network security policy dictates, then network communication between hosts is\n  restricted via ipchains or other firewall mechanism.  This allows\n  simpler Backend and Nginx configuration files.  The reader has at least a basic understanding of JSON formatting and the Linux OS  Running on Ubuntu 14.04 or similar.  If using RedHat, use 'yum' rather than 'apt-get' for software management.  You have version 2.2.1 or newer of SlamData source code.   If your IP addresses differ, change as appropriate.", 
            "title": "Assumptions"
        }, 
        {
            "location": "/securing-slamdata/#architecture-overview", 
            "text": "As can be noted from the above diagram, the network communications path is straight forward:    A request comes into SlamData running under Nginx.    Nginx authenticates the user via standard http auth.    After appropriate authentication, Nginx allows the user into the SlamData application, which communicates directly to the Backend's web API.    The backend runs the appropriate tasks on the data source, MongoDB in this case, and returns the results back upstream, through Nginx to the client.    For increased security, this configuration assumes the reader has setup appropriate network or OS-level restrictions that will deny access to requests other than the system upstream from it.  For instance, the MongoDB server should only allow requests to port 27017 from IP 192.168.138.210 (the Backend host).  Similarly, the Backend should only allow requests to port 8080 from IP 192.168.138.200 (the SlamData / Nginx host).  This setup is not covered in this guide and is left to the reader to implement.", 
            "title": "Architecture Overview"
        }, 
        {
            "location": "/securing-slamdata/#setting-up-the-backend", 
            "text": "The first step is to download the Backend and build the source on the system that will\nbe hosting it.", 
            "title": "Setting Up The Backend"
        }, 
        {
            "location": "/securing-slamdata/#download-and-build-the-backend", 
            "text": "$ git clone https://github.com/slamdata/quasar\n$ cd quasar\n$ ./sbt test\n$ ./sbt 'project web' oneJar\n$ ./sbt 'project core' oneJar  These commands will download the latest source code, run the test suite,\nand build both the Web and Core projects jar files.", 
            "title": "Download and Build the Backend"
        }, 
        {
            "location": "/securing-slamdata/#configure", 
            "text": "Configure the Backend server to connect to MongoDB.  Assuming there is a MongoDB\ndatabased called 'testdb' running on 192.168.138.220, your configuration file may\nbe called quasar-config.json and look like this:  {\n  \"mountings\": {\n      \"/local\": {\n          \"mongodb\": {\n              \"connectionUri\": \"mongodb://192.168.138.220/testdb\"\n          }\n      }\n  },\n  \"server\": { \"port\": 8080 }\n}  For further details on the format of the configuration file, please see the\nBackend  Configuration  documentation.", 
            "title": "Configure"
        }, 
        {
            "location": "/securing-slamdata/#testing-the-backend", 
            "text": "", 
            "title": "Testing the Backend"
        }, 
        {
            "location": "/securing-slamdata/#start-the-core-jar-file", 
            "text": "From the Backend server, run the core jar file to verify you have connectivity and your mounting is correct:  java -jar ~/quasar/core/target/scala-2.11/core_2.11-2.2.1-SNAPSHOT-one-jar.jar ~/quasar-config.json  Once launched, a  REPL  console will appear representing a virtual file system where each MongoDB database is a directory, and each database directory contains one or more MongoDB collections.  Notice how the the OS-like file system commands and SQL commands are executed directly after the $ prompt:  \ud83d\udcaa $ ls\nlocal@\n\ud83d\udcaa $ cd local\n\ud83d\udcaa $ ls\nlocal/\ntestdb/\n\ud83d\udcaa $ cd testdb\n\ud83d\udcaa $ ls\ncoll1\n\ud83d\udcaa $ select * from coll1;\nMongo\ndb.coll1.find();\n\n\nQuery time: 0.0s\n name    | age   | gender  | minor  |\n---------|-------|---------|--------|\n Johnny  |  42.0 | male    |  false |\n Jenny   |  27.0 | female  |  false |\n Deb     |  33.0 | female  |  false |\n Billy   |  15.0 | male    |   true |", 
            "title": "Start the Core jar file"
        }, 
        {
            "location": "/securing-slamdata/#start-the-web-jar-file", 
            "text": "Once you have verified proper connectivity between the Backend and MongoDB, stop the Core jar file and now start the Web jar file with a slightly different syntax to point to the configuration file:  java -jar ~/quasar/web/target/scala-2.11/web_2.11-2.2.1-SNAPSHOT-one-jar.jar -c ~/quasar-config.json  Congratulations!  You now have two of the three necessary systems up and running for this configuration.", 
            "title": "Start the Web jar file"
        }, 
        {
            "location": "/securing-slamdata/#install-pre-requisites", 
            "text": "You should now be working on the system that will be hosting Nginx and SlamData. If you do not already have npm or node installed there, do so first.  On Linux:  $ sudo apt-get install npm\n$ sudo apt-get install nodejs-legacy  On Mac:  $ brew install npm\n$ brew install nodejs  Once npm is installed, utilize it to install  Bower , Gulp  and  PureScript :  $ npm install bower -g\n$ npm install gulp -g\n$ npm install purescript -g", 
            "title": "Install Pre-requisites"
        }, 
        {
            "location": "/securing-slamdata/#download-and-build-slamdata", 
            "text": "Now that npm, node, bower, gulp and PureScript are installed, download the SlamData source and compile:  $ git clone https://github.com/slamdata/slamdata\n$ cd slamdata\n$ bower install\n$ npm install\n$ gulp  When gulp completes, you should have a full application under the 'public' directory:  [/Users/me/slamdata]$ ls public\ncss           fonts         img           index.html    js            notebook.html  It may be safest to copy this directory and place it under a directory with separate permissions for a more secure environment.  Whatever directory you use will be considered your web root directory in future steps.", 
            "title": "Download and Build SlamData"
        }, 
        {
            "location": "/securing-slamdata/#installing-nginx", 
            "text": "", 
            "title": "Installing Nginx"
        }, 
        {
            "location": "/securing-slamdata/#os-x", 
            "text": "On OS X systems, consider using  HomeBrew  to install Nginx:  $ brew install nginx", 
            "title": "OS X"
        }, 
        {
            "location": "/securing-slamdata/#redhat-centos", 
            "text": "On RedHat or CentOS systems:  $ sudo yum install nginx", 
            "title": "Redhat / CentOS"
        }, 
        {
            "location": "/securing-slamdata/#ubuntu-debian", 
            "text": "On Ubuntu or Debian systems:  $ sudo apt-get install nginx", 
            "title": "Ubuntu / Debian"
        }, 
        {
            "location": "/securing-slamdata/#configuring-nginx", 
            "text": "There are two main reasons we'll modify the Nginx configuration file in this guide:    To force user authentication, thus restricting access to known individuals    To redirect queries to the Backend engine on another host, thus limiting the\n   access path to the Backend API to individuals authenticated with Nginx.    This example will use the 'default' Nginx site configuration. Nginx has many configuration files and is a versatile tool, please contact your Nginx application administrator if you have questions, or visit the Nginx web site.  If Nginx is already running, stop it:  sudo service nginx stop", 
            "title": "Configuring Nginx"
        }, 
        {
            "location": "/securing-slamdata/#setting-up-authentication", 
            "text": "To allow http authentication, we'll need to create a file which stores the names and passwords of allowed individuals.  To do this, use the apache2-utils package which provides those tools:  sudo apt-get install apache2-utils  Now create the htpasswd file we'll use to store the encrypted data:  sudo htpasswd -c /etc/nginx/.htpasswd exampleuser  Replace 'exampleuser' with a real username.  You'll then be prompted for a password and verification password.  This creates the file /etc/nginx/.htpasswd which we will reference in the Nginx configuration file below.", 
            "title": "Setting up Authentication"
        }, 
        {
            "location": "/securing-slamdata/#nginx-configuration-file", 
            "text": "Assuming the Nginx site configuration file is located at /etc/nginx/sites-available/default, replace the contents with the following code, making adjustments where necessary of course:  server {\n  listen 80 default_server;\n  listen [::]:80 default_server ipv6only=on;\n\n  server_name your_server_name;\n\n  client_max_body_size 1024M;\n\n  location / {\n    auth_basic \"Restricted\";\n    auth_basic_user_file /etc/nginx/.htpasswd;\n    root /slamdata/public;\n    try_files $uri $uri/ @backend;\n  }\n\n  location @backend {\n    proxy_set_header X-Forwarder-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_pass http://192.168.138.210:8080;\n  }\n}  Pay close attention to the 'root' directive above.  Replace the value with the web root directory referenced earlier. The configuration above ensures the following important actions:    Nginx runs on port 80    Enables http authentication (lines beginning with 'auth_basic')    Nginx acts as a reverse proxy to the Backend service. This can either be\n   on a remote host (as indicated above) or your the same host as Nginx.    Save the configuration and start or restart Nginx:  sudo service nginx restart  If your network firewall is setup properly, the Backend should be shielded from all requests except those coming directly from the Nginx host.  Additionally all requests coming from the Nginx host should only originate from authenticated users via http authentication. You may test the SlamData / Nginx HTTP authorization by going to the URL:  http://192.168.138.200  You should be immediately prompted for a username and password.  Upon successful authorization you should see the SlamData UI:   Note that you are sending requests to Nginx (IP .200), which authenticates a username and then sends the request to the Backend (IP .210), then returns the results directly to\nthe browser.  The browser itself is not redirected as that would defeat the purpose of securing with Nginx.", 
            "title": "Nginx Configuration File"
        }, 
        {
            "location": "/troubleshooting-faq/", 
            "text": "Troubleshooting FAQ\n\n\n\n\n\n\nConfiguration File Locations\n\n\nUpon initial launch, SlamData will not have a configuration file.  Once a valid database mount has been configured, a file will be created and used to store those mount points.  See below for the location of that\nconfiguration file.Unless specified on the command line, SlamData will look for its configuration in the following locations by default:\n\n\nWindows:\n\n\n%HOMEDIR%\\AppData\\Local\\quasar\\quasar-config.json\n\n\n\nMac OS X:\n\n\n$HOME/Library/Application Support/quasar/quasar-config.json\n\n\n\nLinux:\n\n\n$HOME/.config/quasar/quasar-config.json\n\n\n\nNote: Do not modify this file by hand unless you have first made a backup.  If you modify this file while SlamData is running, your changes may be overwritten.\n\n\n\n\n\n\nLog File Locations\n\n\nSlamData has a single log file whose location depends upon the OS.  Replace \nversion\n below with the actual version number that is running.\n\n\nWindows:\n\n\nC:\\Program Files (x86)\\slamdata \nversion\n/slamdata-\nversion\n.log\n\n\n\nLinux:\n\n\n$HOME/slamdata\nversion\n/slamdata-\nversion\n.log\n\n\n\nMac OS X:\n\n\n/Applications/SlamData \nversion\n.app/Contents/java/app/slamdata-\nversion\n.log\n\n\n\n\n\n\n\nSlamData Won't Start\n\n\nThis is typically caused by an invalid database mount.  Either the database is not currently available, or a previously configured mount is no longer valid.  Locate the \nconfiguration file\n and if necessary modify the file by hand, or if you wish to erase all previously configured mounts, you may simply rename or delete the file and restart SlamData.\n\n\n\n\n\n\nSlamData URL\n\n\nWhen SlamData starts on Windows and Mac OS X, a browser window (or new tab) should open with the appropriate URL based on the port defined in the configuration file. Unless the port has been modified, the URL will likely be as follows, replacing servername with the actual host name:\n\n\nhttp://servername:20223/slamdata/index.html\n\n\n\n\n\n\n\n\nHow do I see which version I'm running?\n\n\nYou can simply look at your title bar in your browser window.  The title of the web page should include it.\n\n\n\n\n\n\nSlamData on Amazon EC2 / Microsoft Azure, etc.\n\n\nWhen running SlamData with a hosting provider, including Amazon EC2, the most common error encountered is a security policy misconfiguration.  SlamData will need to connect to your database over the same port that a standard database client does.\n\n\nKeep in mind that the database server and the SlamData server do not need to run on the same system, though there is no problem with that either.  Follow this simple checklist to ensure network problems are minimized:\n\n\nVerify the security policy for the database server is:\n\n\n\n\naccepting incoming connections from the SlamData server IP address\n\n\naccepting incoming connections on the correct port\n\n\n\n\nIf you are still unable to connect to your hosted database:\n\n\n\n\nVerify you can connect with a standard database client from any system.\n\n\nNext connect with a standard database client from the same system SlamData is running on.\n\n\n\n\n\n\n\n\nSlamData Notebook Won't Delete\n\n\nWhen Notebooks in version 2.3.3 or earlier were renamed or deleted, sometimes the view entries associated were not updated in the configuration file.\n\n\nIn version 2.4 and newer, this is no longer an issue.  It is a good idea to review your configuration file, removing any now-defunct entries relating to views associated with renamed or deleted notebooks.", 
            "title": "Troubleshooting FAQ"
        }, 
        {
            "location": "/troubleshooting-faq/#troubleshooting-faq", 
            "text": "", 
            "title": "Troubleshooting FAQ"
        }, 
        {
            "location": "/troubleshooting-faq/#configuration-file-locations", 
            "text": "Upon initial launch, SlamData will not have a configuration file.  Once a valid database mount has been configured, a file will be created and used to store those mount points.  See below for the location of that\nconfiguration file.Unless specified on the command line, SlamData will look for its configuration in the following locations by default:  Windows:  %HOMEDIR%\\AppData\\Local\\quasar\\quasar-config.json  Mac OS X:  $HOME/Library/Application Support/quasar/quasar-config.json  Linux:  $HOME/.config/quasar/quasar-config.json  Note: Do not modify this file by hand unless you have first made a backup.  If you modify this file while SlamData is running, your changes may be overwritten.", 
            "title": "Configuration File Locations"
        }, 
        {
            "location": "/troubleshooting-faq/#log-file-locations", 
            "text": "SlamData has a single log file whose location depends upon the OS.  Replace  version  below with the actual version number that is running.  Windows:  C:\\Program Files (x86)\\slamdata  version /slamdata- version .log  Linux:  $HOME/slamdata version /slamdata- version .log  Mac OS X:  /Applications/SlamData  version .app/Contents/java/app/slamdata- version .log", 
            "title": "Log File Locations"
        }, 
        {
            "location": "/troubleshooting-faq/#slamdata-wont-start", 
            "text": "This is typically caused by an invalid database mount.  Either the database is not currently available, or a previously configured mount is no longer valid.  Locate the  configuration file  and if necessary modify the file by hand, or if you wish to erase all previously configured mounts, you may simply rename or delete the file and restart SlamData.", 
            "title": "SlamData Won't Start"
        }, 
        {
            "location": "/troubleshooting-faq/#slamdata-url", 
            "text": "When SlamData starts on Windows and Mac OS X, a browser window (or new tab) should open with the appropriate URL based on the port defined in the configuration file. Unless the port has been modified, the URL will likely be as follows, replacing servername with the actual host name:  http://servername:20223/slamdata/index.html", 
            "title": "SlamData URL"
        }, 
        {
            "location": "/troubleshooting-faq/#how-do-i-see-which-version-im-running", 
            "text": "You can simply look at your title bar in your browser window.  The title of the web page should include it.", 
            "title": "How do I see which version I'm running?"
        }, 
        {
            "location": "/troubleshooting-faq/#slamdata-on-amazon-ec2-microsoft-azure-etc", 
            "text": "When running SlamData with a hosting provider, including Amazon EC2, the most common error encountered is a security policy misconfiguration.  SlamData will need to connect to your database over the same port that a standard database client does.  Keep in mind that the database server and the SlamData server do not need to run on the same system, though there is no problem with that either.  Follow this simple checklist to ensure network problems are minimized:  Verify the security policy for the database server is:   accepting incoming connections from the SlamData server IP address  accepting incoming connections on the correct port   If you are still unable to connect to your hosted database:   Verify you can connect with a standard database client from any system.  Next connect with a standard database client from the same system SlamData is running on.", 
            "title": "SlamData on Amazon EC2 / Microsoft Azure, etc."
        }, 
        {
            "location": "/troubleshooting-faq/#slamdata-notebook-wont-delete", 
            "text": "When Notebooks in version 2.3.3 or earlier were renamed or deleted, sometimes the view entries associated were not updated in the configuration file.  In version 2.4 and newer, this is no longer an issue.  It is a good idea to review your configuration file, removing any now-defunct entries relating to views associated with renamed or deleted notebooks.", 
            "title": "SlamData Notebook Won't Delete"
        }, 
        {
            "location": "/sql-squared-reference/", 
            "text": "SQL\u00b2 Reference\n\n\n \n\n\nIntroduction\n\n\nSQL\u00b2 is a subset of ANSI SQL, designed for queries into NoSQL databases.\n\n\nSQL\u00b2 has support for every major SQL SELECT clause, such as \nAS\n, \nWHERE\n, \nJOIN\n,\n\nGROUP BY\n, \nHAVING\n, \nLIMIT\n, \nOFFSET\n, \nCROSS\n, etc. It also contains many standard\nSQL functions and operators. It follows \nPostgreSQL\n\nwhere SQL dialects diverge.\n\n\n\n\n \n\n\nData Types\n\n\nThe following data types are used by SQL\u00b2.\n\n\nNote:\n\n\n\n\nSome data types are not natively supported by all databases.\nInstead, they are emulated by SlamData, meaning that you can use them\nas if they were supported by the database.\n\n\n\n\nMDB\n = Native MongoDB Support\n\n\nXYZ\n = Native XYZ DB Support (example for future databases)\n\n\n\n\n\n\n\n\nType\n\n\nDescription\n\n\nExamples\n\n\nMDB\n\n\nXYZ\n\n\n\n\n\n\n\n\n\n\nNull\n\n\nIndicates missing information.\n\n\nnull\n\n\nYes\n\n\n???\n\n\n\n\n\n\nBoolean\n\n\ntrue or false\n\n\ntrue\n, \nfalse\n\n\nYes\n\n\n???\n\n\n\n\n\n\nInteger\n\n\nWhole numbers (no fractional component)\n\n\n1\n, \n-2\n\n\nYes\n\n\n???\n\n\n\n\n\n\nDecimal\n\n\nDecimal numbers (optional fractional components)\n\n\n1.0\n, \n-2.19743\n\n\nYes\n\n\n???\n\n\n\n\n\n\nString\n\n\nText\n\n\n\"221B Baker Street\"\n\n\nYes\n\n\n???\n\n\n\n\n\n\nDateTime\n\n\nDate and time, in ISO8601 format\n\n\nTIMESTAMP(\"2004-10-19 10:23:54\")\n\n\nYes\n\n\n???\n\n\n\n\n\n\nTime\n\n\nTime in the format HH:MM:SS.\n\n\nTIME(\"10:23:54\")\n\n\nNo\n\n\n???\n\n\n\n\n\n\nDate\n\n\nDate in the format YYYY-MM-DD\n\n\nDATE(\"2004-10-19)\"\n\n\nNo\n\n\n???\n\n\n\n\n\n\nInterval\n\n\nTime interval, in ISO8601 format\n\n\nINTERVAL(\"P3DT4H5M6S\")\n\n\nNo\n\n\n???\n\n\n\n\n\n\nObject ID\n\n\nUnique object identifier.\n\n\nOID(\"507f1f77bcf86cd799439011\")\n\n\nYes\n\n\n???\n\n\n\n\n\n\nOrdered Set\n\n\nOrdered list with no duplicates allowed\n\n\n(1, 2, 3)\n\n\nNo\n\n\n???\n\n\n\n\n\n\nArray\n\n\nOrdered list with duplicates allowed\n\n\n[1, 2, 2]\n\n\nYes\n\n\n???\n\n\n\n\n\n\n\n\n\n\n\n\nClauses, Operators, and Functions\n\n\nThe following clauses are supported:\n\n\n\n\n\n\n\n\nType\n\n\nClauses\n\n\n\n\n\n\n\n\n\n\nBasic\n\n\nSELECT\n, \nAS\n, \nFROM\n\n\n\n\n\n\nJoins\n\n\nLEFT OUTER JOIN\n, \nRIGHT OUTER JOIN\n, \nINNER JOIN\n, \nFULL JOIN\n, \nCROSS\n\n\n\n\n\n\nFiltering\n\n\nWHERE\n\n\n\n\n\n\nGrouping\n\n\nGROUP BY\n, \nHAVING\n\n\n\n\n\n\nConditional\n\n\nCASE\n , \nWHEN\n, \nDEFAULT\n\n\n\n\n\n\nPaging\n\n\nLIMIT\n, \nOFFSET\n\n\n\n\n\n\nSorting\n\n\nORDER BY\n , \nDESC\n, \nASC\n\n\n\n\n\n\n\n\nThe following operators are supported:\n\n\n\n\n\n\n\n\nType\n\n\nOperators\n\n\n\n\n\n\n\n\n\n\nNumeric\n\n\n+\n, \n-\n, \n*\n, \n/\n, \n%\n\n\n\n\n\n\nString\n\n\n~\n , \n~*\n, \n!~\n, \n!~*\n, \nLIKE\n, \n||\n\n\n\n\n\n\nArray\n\n\n||\n, \n[ ... ]\n\n\n\n\n\n\nRelational\n\n\n=\n, \n=\n, \n=\n, \n, \nBETWEEN\n, \nIN\n, \nNOT IN\n\n\n\n\n\n\nBoolean\n\n\nAND\n, \nOR\n, \nNOT\n\n\n\n\n\n\nProjection\n\n\nfoo.bar\n, \nfoo[2]\n, \nfoo{*}\n, \nfoo[*]\n\n\n\n\n\n\nDate/Time\n\n\nTIMESTAMP\n, \nDATE\n, \nINTERVAL\n, \nTIME\n\n\n\n\n\n\nIdentity\n\n\nOID\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\n~\n , \n~*\n, \n!~\n, and \n!~*\n are regular expression operators.\n\n~*\n, \n!~\n, and \n!~*\n are preliminary and may not work in the current release.\n\n\n\n\nAlso Note:\n\n\n\n\nThe \n||\n operator for strings will concatenate two strings; for example,\nyou can create a full name from a first and last name property:\n\nc.firstName || ' ' || c.lastName\n. The \n||\n operator for arrays will concatenate two arrays;\nfor example, if \nxy\n is an array with two values, then  \nc.xy || [0]\n will create an\narray with three values, where the third value is zero.\n\n\n\n\nThe following functions are supported:\n\n\n\n\n\n\n\n\nType\n\n\nFunctions\n\n\n\n\n\n\n\n\n\n\nString\n\n\nCONCAT\n, \nLOWER\n, \nUPPER\n, \nSUBSTRING\n, \nLENGTH\n, \nSEARCH\n\n\n\n\n\n\nDateTime\n\n\nDATE_PART\n, \nTO_TIMESTAMP\n\n\n\n\n\n\nNulls\n\n\nCOALESCE\n\n\n\n\n\n\nArrays\n\n\nARRAY_LENGTH\n, \nFLATTEN_ARRAY\n\n\n\n\n\n\nObjects\n\n\nFLATTEN_OBJECT\n\n\n\n\n\n\nSet-Level\n\n\nDISTINCT\n, \nDISTINCT_BY\n\n\n\n\n\n\nAggregation\n\n\nCOUNT\n, \nSUM\n, \nMIN\n, \nMAX\n, \nAVG\n\n\n\n\n\n\nIdentity\n\n\nSQUASH\n\n\n\n\n\n\n\n\n\n\n\n\nSyntax Changes in Version 2.5\n\n\nWhen SlamData 2.5 was released in early 2016 the SQL\u00b2 syntax changed slightly.  Please\nmake note of the following syntax to avoid problems in queries:\n\n\nQuery paths must be surrounded by backward-ticks \n`\n on both ends of the path.\n\n\nExample:\n\n\nSELECT * FROM `/users`\n\n\n\n\nWhen specifying a string in any context surround it by quotes \n\"\n on both ends.\n\n\nExample:\n\n\nSELECT * FROM `/users` WHERE first_name = \nJoe\n\n\n\n\n\nWhen specifying a single character, and not a full string, in any context, surround it by single ticks \n'\n on both ends.\n\n\nExample:\n\n\nSELECT * FROM `/users` WHERE middle_initial = 'A'\n\n\n\n\nWhen using functions such as \nDATE\n, \nDATETIME\n, \nTIMESTAMP\n, etc that require a value it must be surrounded by \n(\n and \n)\n.  Single character \n'\n and string \n\"\n quotes still apply.\n\n\nExample:\n\n\nSELECT * FROM `/users`\nWHERE\n    last_login \n DATE(\n2016-01-01\n) AND\n    subscribed = 'Y'\n\n\n\n\n\n\nBasic Selection\n\n\nThe \nSELECT\n statement returns a result set of records from one or more tables.\n\n\nSelect all values from a path\n\n\nTo select all values from a path, use the asterisk (\n*\n).\n\n\nExample:\n\n\nSELECT * FROM `/users`\n\n\n\n\nSelect specific fields from a path\n\n\nTo select specific fields from a path, use the field names, separated by commas.\n\n\nExample:\n\n\nSELECT name, age FROM `/users`\n\n\n\n\nGive a path an alias to refer to in the query\n\n\nFollow the path name with an \nAS\n and an alias name, and then you can use the alias name\nwhen specifying the fields. This is especially useful when you have data from\nmore than one source.\n\n\nExample:\n\n\nSELECT c.name, c.age FROM `/users` AS c\n\n\n\n\n\n\n\n\nFiltering a Result Set\n\n\nYou can filter a result set using the WHERE clause.\nThe following operators are supported:\n\n\n\n\nRelational: \n-\n, \n=\n, \n=\n, \n=\n, \n, \nBETWEEN\n, \nIN\n, \nNOT IN\n\n\nBoolean: \nAND\n, \nOR\n, \nNOT\n\n\n\n\nFiltering using a numeric value:\n\n\nExample:\n\n\nSELECT c.name FROM `/users` AS c WHERE c.age \n 40\n\n\n\n\nFiltering using a string value:\n\n\nExample:\n\n\nSELECT c.name FROM `/users` AS c WHERE c.name = \nSherlock Holmes\n\n\n\n\n\nFiltering using multiple Boolean predicates:\n\n\nExample: \n\n\nSELECT\n  c.name FROM `/users` AS c\nWHERE\n  c.name = \nSherlock Holmes\n AND\n  c.street = \nBaker Street\n\n\n\n\n\n\n\n\n\nNumeric and String Operations\n\n\nYou can use any of the operators or functions listed in the\n\nClauses, Operators, and Functions\n section\non numbers and strings. Some common string operators and functions include:\n\n\n\n\n\n\n\n\nOperator or Function\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n \n\n\nConcatenates\n\n\n\n\n\n\nLOWER\n\n\nConverts to lowercase\n\n\n\n\n\n\nUPPER\n\n\nConverts to uppercase\n\n\n\n\n\n\nSUBSTRING\n\n\nReturns a substring\n\n\n\n\n\n\nLENGTH\n\n\nReturns length of string\n\n\n\n\n\n\n\n\nExamples:\n\n\nUsing mathematical operations:\n\n\nSELECT c.age + 2 * 1 / 4 % 2 FROM `/users` AS c\n\n\n\n\nConcatenating strings:\n\n\nSELECT c.firstName || ' ' || c.lastName AS name FROM `/users` AS c\n\n\n\n\nFiltering by fuzzy string comparison using the \nLIKE\n operator:\n\n\nSELECT * FROM `/users` AS c WHERE c.firstName LIKE = \n%Joan%\n\n\n\n\n\nFiltering by regular expression:\n\n\nSELECT * FROM `/users` AS c WHERE c.firstName ~ \n[sS]h+\n\n\n\n\n\n\n\n\n\nDates and Times\n\n\nFilter by dates and times using the \nTIMESTAMP\n, \nTIME\n, and \nDATE\n operators. Also, you\ncan also use the \nDATEPART\n operator for selection to select part of a date, such as the day.\n\n\nNote:\n\n\n\n\nSome databases will automatically convert strings into dates or date/times.\nSlamData does not perform this conversion, since the underlying database has no schema\nand no fixed type for any field. As a result, an expression like \nWHERE ts \n \"2015-02-10\"\n\ncompares string-valued \nts\n fields with the string \n\"2015-02-10\"\n instead of a date comparison.\n\n\nIf you want to embed literal dates, timestamps, etc. into your SQL queries, you should use the time\nconversion operators, which accept a string and return value of the appropriate type.\nFor example, the above snippet could be converted to \nWHERE ts \n DATE(\"2015-02-10\")\n, which\nlooks for date-valued \nts\n fields and compares them with the date \n2015-02-10\n.\n\n\n\n\nNOTE for MongoDB Users\n:\n\n\n\n\nIf your MongoDB data does not use MongoDB's native date/time type, and instead, you store your timestamps as epoch milliseconds in a numeric value, then you should either compare numbers or use the \nTO_TIMESTAMP\n function.\n\n\n\n\nFilter based on a timestamp (date and time)\n\n\nUse the \nTIMESTAMP\n operator to convert a string into a date and time. The string should have\nthe format \nYYYY-MM-DDTHH:MM:SS\n.\n\n\nExample:\n\n\nSELECT * FROM `/log/events` AS c WHERE c.ts \n TIMESTAMP(\n2015-04-29T15:16:55\n)\n\n\n\n\nFilter based on a time\n\n\nUse the \nTIME\n operator to convert a string into a time. The string should have\nthe format \nHH:MM:SS\n.\n\n\nExample:\n\n\nSELECT * FROM `/log/events` AS c WHERE c.ts \n TIME(\n15:16:55\n)\n\n\n\n\nFilter based on a date\n\n\nUse the \nDATE\n operator to convert a string into a date. The string should have\nthe format \nYYYY-MM-DD\n.\n\n\nExample:\n\n\nSELECT * FROM `/log/events` AS c WHERE c.ts \n DATE(\n2015-04-29\n)\n\n\n\n\nFilter based on part of a date\n\n\nUse the \nDATE_PART\n function to select part of a date. \nDATE_PART\n has two arguments: a\nstring that indicates what part of the date or time that you want and a timestamp field.\nValid values for the first argument are century, day, decade,\n\ndow\n (day of week), \ndoy\n (day of year), \nhour\n, \nisodoy\n, \nmicroseconds\n, \nmillenium\n, \nmilliseconds\n,\n\nminute\n, \nmonth\n, \nquarter\n, \nsecond\n, and \nyear\n.\n\n\nExample:\n\n\nSELECT DATE_PART(\nday\n, c.ts) FROM `/log/events` AS c\n\n\n\n\nFilter based on a Unix epoch\n\n\nUse the \nTO_TIMESTAMP\n function to convert Unix epoch (milliseconds) to a timestamp.\n\n\nExample:\n\n\nSELECT * FROM `/log/events` AS c WHERE c.ts \n TO_TIMESTAMP(1446335999)\n\n\n\n\n\n\n\n\nGrouping\n\n\nSQL\u00b2 allows you to group data by fields and by date parts.\n\n\nGroup based on a single field\n\n\nUse \nGROUP BY\n to group results by a field.\n\n\nExample:\n\n\nSELECT\n    c.age,\n    COUNT(*) AS cnt\nFROM `/users` AS c\nGROUP BY c.age\n\n\n\n\nGroup based on multiple fields\n\n\nYou can group by multiple fields with a comma-separated list of fields after \nGROUP BY\n.\n\n\nExample:\n\n\nSELECT\n    c.age,\n    c.gender,\n    COUNT(*) AS cnt\nFROM `/users` AS c\nGROUP BY c.age, c.gender\n\n\n\n\nGroup based on date part\n\n\nUse the \nDATE_PART\n function to group by a part of a date, such as the month.\n\n\nExample:\n\n\nSELECT\n    DATE_PART(\nday\n, c.ts) AS day,\n    COUNT(*) AS cnt\nFROM `/log/events` AS c\nGROUP BY DATE_PART(\nday\n, c.ts)\n\n\n\n\nFilter within a group\n\n\nFilter results within a group by adding a \nHAVING\n clause followed by a Boolean predicate.\n\n\nExample:\n\n\nSELECT\n    DATE_PART(\nday\n, c.ts) AS day,\n    COUNT(*) AS cnt\nFROM `/prod/purger/events` AS c\nGROUP BY DATE_PART(\nday\n, c.ts)\nHAVING c.gender = \nfemale\n\n\n\n\n\nDouble grouping\n\n\nPerform double-grouping operations by putting operators inside other operators.\nThe inside operator will be performed on each group created by the \nGROUP BY\n clause,\nand the outside operator will be performed on the results of the inside operator.\n\n\nExample:\n\n\nThis query returns the average population of states. The outer aggregation function\n(AVG) operates on the results of the inner aggregation (\nSUM\n) and \nGROUP BY\n clause.\n\n\nSELECT AVG(SUM(pop)) FROM `/population` GROUP BY state\n\n\n\n\n\n\n\n\nNested Data and Arrays\n\n\nUnlike a relational database many NoSQL databases allow data to be nested (that is, data can be\nobjects) and to contain arrays.\n\n\nNesting\n\n\nNesting is represented by levels separated by a period (\n.\n).\n\n\nExample:\n\n\nSELECT c.profile.address.street.number FROM `/users` AS c\n\n\n\n\nArrays\n\n\nArray elements are represented by the array index in square brackets (\n[n]\n).\n\n\nExample:\n\n\nSELECT c.profile.allAddress[0].street.number FROM `/users` AS c\n\n\n\n\nFlattening\n\n\nYou can extract all elements of an array or all field values simultaneously, essentially\nremoving levels and flattening the data. Use the asterisk in square brackets (\n[*]\n)\nto extract all array elements.\n\n\nExample:\n\n\nSELECT c.profile.allAddresses[*] FROM `/users` AS c\n\n\n\n\nUse the asterisk in curly brackets (\n{*}\n) to extract all field values.\n\n\nExample:\n\n\nSELECT c.profile.{*} FROM `/users` AS c\n\n\n\n\nFiltering using arrays\n\n\nYou can filter using data in all array elements by using the asterisk in square brackets (\n[*]\n)  in\na \nWHERE\n clause.\n\n\nExample:\n\n\nSELECT DISTINCT * FROM `/users` AS c WHERE c.profile.allAddresses[*].street.number = \n221B\n\n\n\n\n\n\n\n\n\nPagination and Sorting\n\n\nPagination\n\n\nPagination is used to break large return results into smaller chunks. Use the \nLIMIT\n operator to\nset the number of results to be returned and the \nOFFSET\n operator to set the index at which the\nresults should start.\n\n\nExample (Limit results to 20 entries):\n\n\nSELECT * FROM `/users` LIMIT 20\n\n\n\n\nExample (Return the 100th to 119th entry):\n\n\nSELECT * FROM `/users` OFFSET 100 LIMIT 20\n\n\n\n\nSorting\n\n\nUse the \nORDER BY\n clause to sort the results. You can specify one or more fields for sorting, and\nyou can use operators in the \nORDER BY\n arguments. Use \nASC\n for ascending sorting and \nDESC\n for decending\nsorting.\n\n\nExample (Sort users by ascending age):\n\n\nSELECT * FROM `/users` ORDER BY age ASC\n\n\n\n\nExample (Sort users by last digit in age, descending, and full name, ascending):\n\n\nSELECT * FROM `/users`\nORDER BY age % 10 DESC, firstName + lastName ASC\n\n\n\n\n\n\n\n\nJoining Collections\n\n\nUse the \nJOIN\n operator to join different collections.\n\n\nThe \nJOIN\n operator is a powerful way to implement joins in non-relational databases such as MongoDB.  There is no enforced limit to how many collections or tables can be joined in a query but common sense should prevail based on the size of collections.\n\n\nExamples:\n\n\nThis example returns the names of employees and the names of the departments they belong to by\nmatching up the employee deparment ID with the department's ID, where both IDs are ObjectID types.\n\n\nSELECT\n    emp.name,\n    dept.name\nFROM `/employees` AS emp\nJOIN `/departments` AS dept ON dept._id = emp.departmentId\n\n\n\n\nIf one of the IDs is a string, then use the \nOID\n operator to convert it to an ID.\n\n\nSELECT\n    emp.name,\n    dept.name\nFROM `/employees` AS emp\nJOIN `/departments` AS dept ON dept._id = OID(emp.departmentId)\n\n\n\n\n\n\n\n\nConditionals and Nulls\n\n\nConditionals\n\n\nUse the \nCASE\n expression to provide if-then-else logic to SQL\u00b2. The \nCASE\n sytax is:\n\n\nSELECT (CASE \nfield\n\n    WHEN \nvalue1\n THEN \nresult1\n\n    WHEN \nvalue2\n THEN \nresult2\n\n    ...\n    [ELSE \nelseResult\n\n    END)\nFROM `\npath\n`\n\n\n\n\nExample:\n\n\nThe following example generates a code based on gender string values.\n\n\nSELECT (CASE c.gender\n    WHEN \nmale\n THEN 1\n    WHEN \nfemale\n THEN 2\n    ELSE 3\n    END) AS genderCode\nFROM `/users` AS c\n\n\n\n\nNulls\n\n\nUse the \nCOALESCE\n function to evaluate the arguments in order and return the current value of the first expression that initially does not evaluate to \nNULL\n.\n\n\nExample:\n\n\nThis example returns a full name, if not null, but returns the first name if the full name is null.\n\n\nSELECT COALESCE(c.fullName, c.firstName) AS name FROM `/users` AS c\n\n\n\n\n\n\n\n\nDatabase Specific Notes\n\n\nMongoDB\n\n\nThe _id Field\n\n\nBy default, the \n_id\n field will not appear in a result set. However, you can specify it by selecting the\n\n_id\n field. For example:\n\n\nSELECT _id AS cust_id FROM `/users`\n\n\n\n\nMongoDB has special rules about fields called \n_id\n. For example, they must remain unique, which\nmeans that some queries (such as \nSELECT myarray[*] FROM foo\n) will introduce duplicates that\nMongoDB won't allow. In addition, other queries change the value of \n_id\n (such as grouping).\nSo SlamData manages \n_id\n and treats it as a special field.\n\n\nNote:\n To filter on \n_id\n, you must first convert a string to an object ID,\nby using the \nOID\n function. For example:\n\n\nSELECT * FROM `/foo` WHERE _id = OID(\nabc123\n)", 
            "title": "Reference (SQL\u00b2)"
        }, 
        {
            "location": "/sql-squared-reference/#sql2-reference", 
            "text": "", 
            "title": "SQL\u00b2 Reference"
        }, 
        {
            "location": "/sql-squared-reference/#introduction", 
            "text": "SQL\u00b2 is a subset of ANSI SQL, designed for queries into NoSQL databases.  SQL\u00b2 has support for every major SQL SELECT clause, such as  AS ,  WHERE ,  JOIN , GROUP BY ,  HAVING ,  LIMIT ,  OFFSET ,  CROSS , etc. It also contains many standard\nSQL functions and operators. It follows  PostgreSQL \nwhere SQL dialects diverge.", 
            "title": "Introduction"
        }, 
        {
            "location": "/sql-squared-reference/#data-types", 
            "text": "The following data types are used by SQL\u00b2.  Note:   Some data types are not natively supported by all databases.\nInstead, they are emulated by SlamData, meaning that you can use them\nas if they were supported by the database.   MDB  = Native MongoDB Support  XYZ  = Native XYZ DB Support (example for future databases)     Type  Description  Examples  MDB  XYZ      Null  Indicates missing information.  null  Yes  ???    Boolean  true or false  true ,  false  Yes  ???    Integer  Whole numbers (no fractional component)  1 ,  -2  Yes  ???    Decimal  Decimal numbers (optional fractional components)  1.0 ,  -2.19743  Yes  ???    String  Text  \"221B Baker Street\"  Yes  ???    DateTime  Date and time, in ISO8601 format  TIMESTAMP(\"2004-10-19 10:23:54\")  Yes  ???    Time  Time in the format HH:MM:SS.  TIME(\"10:23:54\")  No  ???    Date  Date in the format YYYY-MM-DD  DATE(\"2004-10-19)\"  No  ???    Interval  Time interval, in ISO8601 format  INTERVAL(\"P3DT4H5M6S\")  No  ???    Object ID  Unique object identifier.  OID(\"507f1f77bcf86cd799439011\")  Yes  ???    Ordered Set  Ordered list with no duplicates allowed  (1, 2, 3)  No  ???    Array  Ordered list with duplicates allowed  [1, 2, 2]  Yes  ???", 
            "title": "Data Types"
        }, 
        {
            "location": "/sql-squared-reference/#clauses-operators-and-functions", 
            "text": "The following clauses are supported:     Type  Clauses      Basic  SELECT ,  AS ,  FROM    Joins  LEFT OUTER JOIN ,  RIGHT OUTER JOIN ,  INNER JOIN ,  FULL JOIN ,  CROSS    Filtering  WHERE    Grouping  GROUP BY ,  HAVING    Conditional  CASE  ,  WHEN ,  DEFAULT    Paging  LIMIT ,  OFFSET    Sorting  ORDER BY  ,  DESC ,  ASC     The following operators are supported:     Type  Operators      Numeric  + ,  - ,  * ,  / ,  %    String  ~  ,  ~* ,  !~ ,  !~* ,  LIKE ,  ||    Array  || ,  [ ... ]    Relational  = ,  = ,  = ,  ,  BETWEEN ,  IN ,  NOT IN    Boolean  AND ,  OR ,  NOT    Projection  foo.bar ,  foo[2] ,  foo{*} ,  foo[*]    Date/Time  TIMESTAMP ,  DATE ,  INTERVAL ,  TIME    Identity  OID     Note:   ~  ,  ~* ,  !~ , and  !~*  are regular expression operators. ~* ,  !~ , and  !~*  are preliminary and may not work in the current release.   Also Note:   The  ||  operator for strings will concatenate two strings; for example,\nyou can create a full name from a first and last name property: c.firstName || ' ' || c.lastName . The  ||  operator for arrays will concatenate two arrays;\nfor example, if  xy  is an array with two values, then   c.xy || [0]  will create an\narray with three values, where the third value is zero.   The following functions are supported:     Type  Functions      String  CONCAT ,  LOWER ,  UPPER ,  SUBSTRING ,  LENGTH ,  SEARCH    DateTime  DATE_PART ,  TO_TIMESTAMP    Nulls  COALESCE    Arrays  ARRAY_LENGTH ,  FLATTEN_ARRAY    Objects  FLATTEN_OBJECT    Set-Level  DISTINCT ,  DISTINCT_BY    Aggregation  COUNT ,  SUM ,  MIN ,  MAX ,  AVG    Identity  SQUASH", 
            "title": "Clauses, Operators, and Functions"
        }, 
        {
            "location": "/sql-squared-reference/#syntax-changes-in-version-25", 
            "text": "When SlamData 2.5 was released in early 2016 the SQL\u00b2 syntax changed slightly.  Please\nmake note of the following syntax to avoid problems in queries:  Query paths must be surrounded by backward-ticks  `  on both ends of the path.  Example:  SELECT * FROM `/users`  When specifying a string in any context surround it by quotes  \"  on both ends.  Example:  SELECT * FROM `/users` WHERE first_name =  Joe   When specifying a single character, and not a full string, in any context, surround it by single ticks  '  on both ends.  Example:  SELECT * FROM `/users` WHERE middle_initial = 'A'  When using functions such as  DATE ,  DATETIME ,  TIMESTAMP , etc that require a value it must be surrounded by  (  and  ) .  Single character  '  and string  \"  quotes still apply.  Example:  SELECT * FROM `/users`\nWHERE\n    last_login   DATE( 2016-01-01 ) AND\n    subscribed = 'Y'", 
            "title": "Syntax Changes in Version 2.5"
        }, 
        {
            "location": "/sql-squared-reference/#basic-selection", 
            "text": "The  SELECT  statement returns a result set of records from one or more tables.", 
            "title": "Basic Selection"
        }, 
        {
            "location": "/sql-squared-reference/#select-all-values-from-a-path", 
            "text": "To select all values from a path, use the asterisk ( * ).  Example:  SELECT * FROM `/users`", 
            "title": "Select all values from a path"
        }, 
        {
            "location": "/sql-squared-reference/#select-specific-fields-from-a-path", 
            "text": "To select specific fields from a path, use the field names, separated by commas.  Example:  SELECT name, age FROM `/users`", 
            "title": "Select specific fields from a path"
        }, 
        {
            "location": "/sql-squared-reference/#give-a-path-an-alias-to-refer-to-in-the-query", 
            "text": "Follow the path name with an  AS  and an alias name, and then you can use the alias name\nwhen specifying the fields. This is especially useful when you have data from\nmore than one source.  Example:  SELECT c.name, c.age FROM `/users` AS c", 
            "title": "Give a path an alias to refer to in the query"
        }, 
        {
            "location": "/sql-squared-reference/#filtering-a-result-set", 
            "text": "You can filter a result set using the WHERE clause.\nThe following operators are supported:   Relational:  - ,  = ,  = ,  = ,  ,  BETWEEN ,  IN ,  NOT IN  Boolean:  AND ,  OR ,  NOT", 
            "title": "Filtering a Result Set"
        }, 
        {
            "location": "/sql-squared-reference/#filtering-using-a-numeric-value", 
            "text": "Example:  SELECT c.name FROM `/users` AS c WHERE c.age   40", 
            "title": "Filtering using a numeric value:"
        }, 
        {
            "location": "/sql-squared-reference/#filtering-using-a-string-value", 
            "text": "Example:  SELECT c.name FROM `/users` AS c WHERE c.name =  Sherlock Holmes", 
            "title": "Filtering using a string value:"
        }, 
        {
            "location": "/sql-squared-reference/#filtering-using-multiple-boolean-predicates", 
            "text": "Example:   SELECT\n  c.name FROM `/users` AS c\nWHERE\n  c.name =  Sherlock Holmes  AND\n  c.street =  Baker Street", 
            "title": "Filtering using multiple Boolean predicates:"
        }, 
        {
            "location": "/sql-squared-reference/#numeric-and-string-operations", 
            "text": "You can use any of the operators or functions listed in the Clauses, Operators, and Functions  section\non numbers and strings. Some common string operators and functions include:     Operator or Function  Description         Concatenates    LOWER  Converts to lowercase    UPPER  Converts to uppercase    SUBSTRING  Returns a substring    LENGTH  Returns length of string     Examples:  Using mathematical operations:  SELECT c.age + 2 * 1 / 4 % 2 FROM `/users` AS c  Concatenating strings:  SELECT c.firstName || ' ' || c.lastName AS name FROM `/users` AS c  Filtering by fuzzy string comparison using the  LIKE  operator:  SELECT * FROM `/users` AS c WHERE c.firstName LIKE =  %Joan%   Filtering by regular expression:  SELECT * FROM `/users` AS c WHERE c.firstName ~  [sS]h+", 
            "title": "Numeric and String Operations"
        }, 
        {
            "location": "/sql-squared-reference/#dates-and-times", 
            "text": "Filter by dates and times using the  TIMESTAMP ,  TIME , and  DATE  operators. Also, you\ncan also use the  DATEPART  operator for selection to select part of a date, such as the day.  Note:   Some databases will automatically convert strings into dates or date/times.\nSlamData does not perform this conversion, since the underlying database has no schema\nand no fixed type for any field. As a result, an expression like  WHERE ts   \"2015-02-10\" \ncompares string-valued  ts  fields with the string  \"2015-02-10\"  instead of a date comparison.  If you want to embed literal dates, timestamps, etc. into your SQL queries, you should use the time\nconversion operators, which accept a string and return value of the appropriate type.\nFor example, the above snippet could be converted to  WHERE ts   DATE(\"2015-02-10\") , which\nlooks for date-valued  ts  fields and compares them with the date  2015-02-10 .   NOTE for MongoDB Users :   If your MongoDB data does not use MongoDB's native date/time type, and instead, you store your timestamps as epoch milliseconds in a numeric value, then you should either compare numbers or use the  TO_TIMESTAMP  function.", 
            "title": "Dates and Times"
        }, 
        {
            "location": "/sql-squared-reference/#filter-based-on-a-timestamp-date-and-time", 
            "text": "Use the  TIMESTAMP  operator to convert a string into a date and time. The string should have\nthe format  YYYY-MM-DDTHH:MM:SS .  Example:  SELECT * FROM `/log/events` AS c WHERE c.ts   TIMESTAMP( 2015-04-29T15:16:55 )", 
            "title": "Filter based on a timestamp (date and time)"
        }, 
        {
            "location": "/sql-squared-reference/#filter-based-on-a-time", 
            "text": "Use the  TIME  operator to convert a string into a time. The string should have\nthe format  HH:MM:SS .  Example:  SELECT * FROM `/log/events` AS c WHERE c.ts   TIME( 15:16:55 )", 
            "title": "Filter based on a time"
        }, 
        {
            "location": "/sql-squared-reference/#filter-based-on-a-date", 
            "text": "Use the  DATE  operator to convert a string into a date. The string should have\nthe format  YYYY-MM-DD .  Example:  SELECT * FROM `/log/events` AS c WHERE c.ts   DATE( 2015-04-29 )", 
            "title": "Filter based on a date"
        }, 
        {
            "location": "/sql-squared-reference/#filter-based-on-part-of-a-date", 
            "text": "Use the  DATE_PART  function to select part of a date.  DATE_PART  has two arguments: a\nstring that indicates what part of the date or time that you want and a timestamp field.\nValid values for the first argument are century, day, decade, dow  (day of week),  doy  (day of year),  hour ,  isodoy ,  microseconds ,  millenium ,  milliseconds , minute ,  month ,  quarter ,  second , and  year .  Example:  SELECT DATE_PART( day , c.ts) FROM `/log/events` AS c", 
            "title": "Filter based on part of a date"
        }, 
        {
            "location": "/sql-squared-reference/#filter-based-on-a-unix-epoch", 
            "text": "Use the  TO_TIMESTAMP  function to convert Unix epoch (milliseconds) to a timestamp.  Example:  SELECT * FROM `/log/events` AS c WHERE c.ts   TO_TIMESTAMP(1446335999)", 
            "title": "Filter based on a Unix epoch"
        }, 
        {
            "location": "/sql-squared-reference/#grouping", 
            "text": "SQL\u00b2 allows you to group data by fields and by date parts.", 
            "title": "Grouping"
        }, 
        {
            "location": "/sql-squared-reference/#group-based-on-a-single-field", 
            "text": "Use  GROUP BY  to group results by a field.  Example:  SELECT\n    c.age,\n    COUNT(*) AS cnt\nFROM `/users` AS c\nGROUP BY c.age", 
            "title": "Group based on a single field"
        }, 
        {
            "location": "/sql-squared-reference/#group-based-on-multiple-fields", 
            "text": "You can group by multiple fields with a comma-separated list of fields after  GROUP BY .  Example:  SELECT\n    c.age,\n    c.gender,\n    COUNT(*) AS cnt\nFROM `/users` AS c\nGROUP BY c.age, c.gender", 
            "title": "Group based on multiple fields"
        }, 
        {
            "location": "/sql-squared-reference/#group-based-on-date-part", 
            "text": "Use the  DATE_PART  function to group by a part of a date, such as the month.  Example:  SELECT\n    DATE_PART( day , c.ts) AS day,\n    COUNT(*) AS cnt\nFROM `/log/events` AS c\nGROUP BY DATE_PART( day , c.ts)", 
            "title": "Group based on date part"
        }, 
        {
            "location": "/sql-squared-reference/#filter-within-a-group", 
            "text": "Filter results within a group by adding a  HAVING  clause followed by a Boolean predicate.  Example:  SELECT\n    DATE_PART( day , c.ts) AS day,\n    COUNT(*) AS cnt\nFROM `/prod/purger/events` AS c\nGROUP BY DATE_PART( day , c.ts)\nHAVING c.gender =  female", 
            "title": "Filter within a group"
        }, 
        {
            "location": "/sql-squared-reference/#double-grouping", 
            "text": "Perform double-grouping operations by putting operators inside other operators.\nThe inside operator will be performed on each group created by the  GROUP BY  clause,\nand the outside operator will be performed on the results of the inside operator.  Example:  This query returns the average population of states. The outer aggregation function\n(AVG) operates on the results of the inner aggregation ( SUM ) and  GROUP BY  clause.  SELECT AVG(SUM(pop)) FROM `/population` GROUP BY state", 
            "title": "Double grouping"
        }, 
        {
            "location": "/sql-squared-reference/#nested-data-and-arrays", 
            "text": "Unlike a relational database many NoSQL databases allow data to be nested (that is, data can be\nobjects) and to contain arrays.", 
            "title": "Nested Data and Arrays"
        }, 
        {
            "location": "/sql-squared-reference/#nesting", 
            "text": "Nesting is represented by levels separated by a period ( . ).  Example:  SELECT c.profile.address.street.number FROM `/users` AS c", 
            "title": "Nesting"
        }, 
        {
            "location": "/sql-squared-reference/#arrays", 
            "text": "Array elements are represented by the array index in square brackets ( [n] ).  Example:  SELECT c.profile.allAddress[0].street.number FROM `/users` AS c", 
            "title": "Arrays"
        }, 
        {
            "location": "/sql-squared-reference/#flattening", 
            "text": "You can extract all elements of an array or all field values simultaneously, essentially\nremoving levels and flattening the data. Use the asterisk in square brackets ( [*] )\nto extract all array elements.  Example:  SELECT c.profile.allAddresses[*] FROM `/users` AS c  Use the asterisk in curly brackets ( {*} ) to extract all field values.  Example:  SELECT c.profile.{*} FROM `/users` AS c", 
            "title": "Flattening"
        }, 
        {
            "location": "/sql-squared-reference/#filtering-using-arrays", 
            "text": "You can filter using data in all array elements by using the asterisk in square brackets ( [*] )  in\na  WHERE  clause.  Example:  SELECT DISTINCT * FROM `/users` AS c WHERE c.profile.allAddresses[*].street.number =  221B", 
            "title": "Filtering using arrays"
        }, 
        {
            "location": "/sql-squared-reference/#pagination-and-sorting", 
            "text": "", 
            "title": "Pagination and Sorting"
        }, 
        {
            "location": "/sql-squared-reference/#pagination", 
            "text": "Pagination is used to break large return results into smaller chunks. Use the  LIMIT  operator to\nset the number of results to be returned and the  OFFSET  operator to set the index at which the\nresults should start.  Example (Limit results to 20 entries):  SELECT * FROM `/users` LIMIT 20  Example (Return the 100th to 119th entry):  SELECT * FROM `/users` OFFSET 100 LIMIT 20", 
            "title": "Pagination"
        }, 
        {
            "location": "/sql-squared-reference/#sorting", 
            "text": "Use the  ORDER BY  clause to sort the results. You can specify one or more fields for sorting, and\nyou can use operators in the  ORDER BY  arguments. Use  ASC  for ascending sorting and  DESC  for decending\nsorting.  Example (Sort users by ascending age):  SELECT * FROM `/users` ORDER BY age ASC  Example (Sort users by last digit in age, descending, and full name, ascending):  SELECT * FROM `/users`\nORDER BY age % 10 DESC, firstName + lastName ASC", 
            "title": "Sorting"
        }, 
        {
            "location": "/sql-squared-reference/#joining-collections", 
            "text": "Use the  JOIN  operator to join different collections.  The  JOIN  operator is a powerful way to implement joins in non-relational databases such as MongoDB.  There is no enforced limit to how many collections or tables can be joined in a query but common sense should prevail based on the size of collections.  Examples:  This example returns the names of employees and the names of the departments they belong to by\nmatching up the employee deparment ID with the department's ID, where both IDs are ObjectID types.  SELECT\n    emp.name,\n    dept.name\nFROM `/employees` AS emp\nJOIN `/departments` AS dept ON dept._id = emp.departmentId  If one of the IDs is a string, then use the  OID  operator to convert it to an ID.  SELECT\n    emp.name,\n    dept.name\nFROM `/employees` AS emp\nJOIN `/departments` AS dept ON dept._id = OID(emp.departmentId)", 
            "title": "Joining Collections"
        }, 
        {
            "location": "/sql-squared-reference/#conditionals-and-nulls", 
            "text": "", 
            "title": "Conditionals and Nulls"
        }, 
        {
            "location": "/sql-squared-reference/#conditionals", 
            "text": "Use the  CASE  expression to provide if-then-else logic to SQL\u00b2. The  CASE  sytax is:  SELECT (CASE  field \n    WHEN  value1  THEN  result1 \n    WHEN  value2  THEN  result2 \n    ...\n    [ELSE  elseResult \n    END)\nFROM ` path `  Example:  The following example generates a code based on gender string values.  SELECT (CASE c.gender\n    WHEN  male  THEN 1\n    WHEN  female  THEN 2\n    ELSE 3\n    END) AS genderCode\nFROM `/users` AS c", 
            "title": "Conditionals"
        }, 
        {
            "location": "/sql-squared-reference/#nulls", 
            "text": "Use the  COALESCE  function to evaluate the arguments in order and return the current value of the first expression that initially does not evaluate to  NULL .  Example:  This example returns a full name, if not null, but returns the first name if the full name is null.  SELECT COALESCE(c.fullName, c.firstName) AS name FROM `/users` AS c", 
            "title": "Nulls"
        }, 
        {
            "location": "/sql-squared-reference/#database-specific-notes", 
            "text": "", 
            "title": "Database Specific Notes"
        }, 
        {
            "location": "/sql-squared-reference/#mongodb", 
            "text": "", 
            "title": "MongoDB"
        }, 
        {
            "location": "/sql-squared-reference/#the-_id-field", 
            "text": "By default, the  _id  field will not appear in a result set. However, you can specify it by selecting the _id  field. For example:  SELECT _id AS cust_id FROM `/users`  MongoDB has special rules about fields called  _id . For example, they must remain unique, which\nmeans that some queries (such as  SELECT myarray[*] FROM foo ) will introduce duplicates that\nMongoDB won't allow. In addition, other queries change the value of  _id  (such as grouping).\nSo SlamData manages  _id  and treats it as a special field.  Note:  To filter on  _id , you must first convert a string to an object ID,\nby using the  OID  function. For example:  SELECT * FROM `/foo` WHERE _id = OID( abc123 )", 
            "title": "The _id Field"
        }, 
        {
            "location": "/slamdown-reference/", 
            "text": "SlamDown Reference\n\n\nThis SlamDown Reference can assist with the proper formatting of SlamDown code to produce static and interactive forms within SlamData.\n\n\n\n\nIntroduction\n\n\nSlamData contains its own markup language called SlamDown, which is useful for creating reports and forms. SlamDown is a subset of \nCommonMark\n, a specification for a highly compatible implementation of \nMarkdown\n.\n\n\nIn addition, SlamDown also includes two extensions to CommonMark: \nform fields\n and \nevaluated SQL\n2\n queries\n.\n\n\nThis reference contains the following sections:\n\n\n\n\nBlock Elements\n\n\nThe following SlamDown elements create blocks of content.\n\n\nHorizontal Rules\n\n\nThree dashes or more create a horizontal line. Put a blank line above and below the dashes.\n\n\nText here\n\n---\n\nMore text here\n\n\n\nresults in:\n\n\nText here\n\n\n\n\nMore text here\n\n\nHeaders\n\n\nUse hash marks (\n#\n) for \nATX headers\n, with one hashmark\nfor each level.\n\n\n# Top level  \n## Second level\n### Third level\n\n\n\nresults in a first, second, and third level heading:\n\n\n\n\nCode Blocks\n\n\nYou can create blocks of code (that is, literal content in monospace font) in two ways:\n\n\nIndented code blocks\n\n\nIndent by four spaces.\n\n\n\n        for (int i =0; i \n<\n 10; i++)\n            sum += myArray[i];\n\n\n\n\nFenced code blocks\n\n\nStart and end with three or more backtick (`) characters.\n\n\n```\nfor (int i =0; i \n 10; i++)\n    sum += myArray[i];\n```\n\n\n\nBoth Indented Code Blocks and Fenced Code Blocks result in:\n\n\nfor (int i =0; i \n 10; i++)\n   sum += myArray[i];\n\n\n\n\nParagraphs\n\n\nParagraphs are separated by a blank line.\n\n\nThis is paragraph 1.\n\nThis is paragraph 2.\n\n\n\nresults in:\n\n\nThis is paragraph 1.\n\n\nThis is paragraph 2.\n\n\nBlock quotes\n\n\nStart with a greater than sign (\n) to create a block quote.\n\n\n This is a block quote.\n\n\n\nresults in:\n\n\n\n\nThis is a block quote.  \n\n\n\n\nLists\n\n\nOrdrered lists start with numbers followed by periods. The actual numbers in the SlamDown do not matter.\nIn the end, they will be displayed with ascending indices.\n\n\n1. First item\n2. Second item\n3. Third item\n\n\n\nresults in:\n\n\n\n\nFirst item\n\n\nSecond item\n\n\nThird item\n\n\n\n\nUnordered lists start with either asterisks (\n*\n), dashes (\n-\n), or pluses (\n+\n). They are\ninterchangeable.\n\n\n* First item\n* Second item\n* Third item\n\n\n\nresults in:\n\n\n\n\nFirst item\n\n\nSecond item\n\n\nThird item\n\n\n\n\n\n\nInline Elements\n\n\nThe following inline elements are supported in SlamDown. In addition to standard Markdown\nelements, there is also the ability to \nevaluate a SQL query\n and put the\nresult into the content.\n\n\nEmphasis and Strong Emphasis\n\n\nSurround content with asterisks (\n*\n) for emphasis and surround it with double asterisks (\n**\n)\nfor strong emphasis.\n\n\nThis is *important*. This is **more important**.\n\n\n\nresults in:\n\n\nThis is \nimportant\n. This is \nmore important\n.\n\n\nLinks\n\n\nLinks contain the link title in square brackets (\n[]\n) and the link destination in\nparentheses (\n()\n).\n\n\n[SlamData](http://slamdata.com)\n\n\n\nresults in:\n\n\nSlamData\n\n\nIf the link title and destination are the same, you can use an autolink, where the URI\nis contained in angle brackets (\n).\n\n\nhttp://slamdata.com\n\n\n\n\nresults in:\n\n\nhttp://slamdata.com\n\n\nImages\n\n\nImages start with an explanation mark (\n!\n), followed by the image description in square brackets\n(\n[]\n) and the image URI in parentheses (\n()\n).\n\n\n![SlamData Logo](https://media.licdn.com/media/p/6/005/088/002/039b9f8.png)\n\n\n\nresults in:\n\n\n\n\nInline code formatting\n\n\nTo add code formatting (literal content with monospace font) inline, put the content between\nbacktick (`) characters.\n\n\nStart SQL statements with `SELECT * FROM`\n\n\n\nresults in:\n\n\nStart SQL statements with \nSELECT * FROM\n\n\nEvaluated SQL Query\n\n\nSlamDown extends CommonMark by allowing you to evaluate a SQL query and insert\nthe results into the rendered content. Start the query with an exclamation point\nand then contain the SQL query between double backtick (`) characters.\n\n\nNote:\n\n\n\n\nNotice how the path to the query below has a space between the backtick that\nends the path and the double backticks that end the query.  This is a necessary\nspace because three backticks in a row start a Fenced Code Block as stated above.\n\n\n\n\nIn the example below, if there are 20 documents in the \n/col\n file, then\n\n\nThere are !``SELECT COUNT(*) FROM `/col` `` documents inside the collection.\n\n\n\n\nresults in:\n\n\nThere are \n20\n documents inside the collection.\n\n\n\n\nForm Elements\n\n\nSlamDown contains a significant addition to CommonMark, which are form elements.\nThis allows for the creation of interactive reports.\n\n\nText Field\n\n\nUse one or more underscores (\n_\n) to create a text input field where a user\ncan add text.\n\n\nFor example, this line creates an input file for a name. You can then refer to the user value with the string variable name \nname\n.\n\n\nname = ________\n\n\n\nOptionally, you can pre-fill the input field with a default value by having\nit after the underscores in parentheses.\nThis line creates an input file for spouse name with a default value of\n\"none\". You can then refer to the user value with the string variable name \nspouse\n.\n\n\nspouse = ________ (none)\n\n\n\nBy default input fields are evaluated as String types.  To enforce a numeric type\nprefix the underscores with the (\n#\n) symbol.  For example:\n\n\nyear = #________\n\n\n\nRadio Buttons\n\n\nUse parentheses followed by text to indicate radio buttons. A set of radio buttons has\nonly one button selected at a time. Indicate which button is selected by putting an \nx\n\nin the parentheses.\n\n\nFor example, this line creates a set of radio buttons with the values \"car\", \"bus\",\nand \"bike\", where \"car\" is marked as the default. The result is stored in the string\nvariable named \ncommute\n for later use.\n\n\ncommute = (x) car () bus () bike\n\n\n\nThis results in:\n\n\n\n\nNote:\n Currently, the default value must be the first value.\n\n\nCheckboxes\n\n\nUse square brackets followed by text to indicate checkboxes. In a set of checkboxes,\neach checkbox operates independently. Use an \nx\n in the square brackets to indicate\nthat the checkbox should be checked by default.\nThe string value returned will be an array of strings in square brackets.\n\n\nFor example, this line creates a set of checkboxes with the values \"Android\", \"iPhone\",\nand \"Blackberry\". The result is stored in the string variable named \nphones\n for later use.\n\n\nphones = [] Android [x] iPhone [x] Blackberry\n\n\n\nIf left as the default, the \nphones\n variable will have the value: \n['iPhone', 'Blackberry']\n.\n\n\nThis results in:\n\n\n\n\nDropdown\n\n\nUse a comma-separated list in curly brackets to indicate a dropdown element.\n\n\nFor example, this line creates a dropdown element with BOS, SFO, and NYC entries.  The result is stored in the string variable named \ncity\n for later use.\n\n\ncity = {BOS, SFO, NYC}\n\n\n\nOptionally, include a default value by listing it in parentheses at the end.\nIn this line, NYC is set as the default.\n\n\ncity = {BOS, SFO, NYC} (NYC)\n\n\n\nThis results in:\n\n\n\n\nDates and Times\n\n\nProvide a date, time or both date \n time selector for users by implementing the following syntax.\n\n\nDate\n\n\nFor example the following line creates a date selector element and stores the value in a variable called \nstart\n:\n\n\nstart = __ - __ - ____ (04-19-2016)\n\n\n\n\nTime\n\n\nThe following lines creates a time selector element:\n\n\nstart = __ : __ (12:30 PM)\n\n\n\n\nDate \n Time\n\n\nThe following line creates both a date and time selector element:\n\n\nstart = __ - __ - ____ __ : __ (06-06-2015 12:00 PM)\n\n\n\n\nThis results in:", 
            "title": "Reference (SlamDown)"
        }, 
        {
            "location": "/slamdown-reference/#slamdown-reference", 
            "text": "This SlamDown Reference can assist with the proper formatting of SlamDown code to produce static and interactive forms within SlamData.", 
            "title": "SlamDown Reference"
        }, 
        {
            "location": "/slamdown-reference/#introduction", 
            "text": "SlamData contains its own markup language called SlamDown, which is useful for creating reports and forms. SlamDown is a subset of  CommonMark , a specification for a highly compatible implementation of  Markdown .  In addition, SlamDown also includes two extensions to CommonMark:  form fields  and  evaluated SQL 2  queries .  This reference contains the following sections:", 
            "title": "Introduction"
        }, 
        {
            "location": "/slamdown-reference/#block-elements", 
            "text": "The following SlamDown elements create blocks of content.", 
            "title": "Block Elements"
        }, 
        {
            "location": "/slamdown-reference/#horizontal-rules", 
            "text": "Three dashes or more create a horizontal line. Put a blank line above and below the dashes.  Text here\n\n---\n\nMore text here  results in:  Text here   More text here", 
            "title": "Horizontal Rules"
        }, 
        {
            "location": "/slamdown-reference/#headers", 
            "text": "Use hash marks ( # ) for  ATX headers , with one hashmark\nfor each level.  # Top level  \n## Second level\n### Third level  results in a first, second, and third level heading:", 
            "title": "Headers"
        }, 
        {
            "location": "/slamdown-reference/#code-blocks", 
            "text": "You can create blocks of code (that is, literal content in monospace font) in two ways:  Indented code blocks  Indent by four spaces.  \n        for (int i =0; i  <  10; i++)\n            sum += myArray[i];  Fenced code blocks  Start and end with three or more backtick (`) characters.  ```\nfor (int i =0; i   10; i++)\n    sum += myArray[i];\n```  Both Indented Code Blocks and Fenced Code Blocks result in:  for (int i =0; i   10; i++)\n   sum += myArray[i];", 
            "title": "Code Blocks"
        }, 
        {
            "location": "/slamdown-reference/#paragraphs", 
            "text": "Paragraphs are separated by a blank line.  This is paragraph 1.\n\nThis is paragraph 2.  results in:  This is paragraph 1.  This is paragraph 2.", 
            "title": "Paragraphs"
        }, 
        {
            "location": "/slamdown-reference/#block-quotes", 
            "text": "Start with a greater than sign ( ) to create a block quote.   This is a block quote.  results in:   This is a block quote.", 
            "title": "Block quotes"
        }, 
        {
            "location": "/slamdown-reference/#lists", 
            "text": "Ordrered lists start with numbers followed by periods. The actual numbers in the SlamDown do not matter.\nIn the end, they will be displayed with ascending indices.  1. First item\n2. Second item\n3. Third item  results in:   First item  Second item  Third item   Unordered lists start with either asterisks ( * ), dashes ( - ), or pluses ( + ). They are\ninterchangeable.  * First item\n* Second item\n* Third item  results in:   First item  Second item  Third item", 
            "title": "Lists"
        }, 
        {
            "location": "/slamdown-reference/#inline-elements", 
            "text": "The following inline elements are supported in SlamDown. In addition to standard Markdown\nelements, there is also the ability to  evaluate a SQL query  and put the\nresult into the content.", 
            "title": "Inline Elements"
        }, 
        {
            "location": "/slamdown-reference/#emphasis-and-strong-emphasis", 
            "text": "Surround content with asterisks ( * ) for emphasis and surround it with double asterisks ( ** )\nfor strong emphasis.  This is *important*. This is **more important**.  results in:  This is  important . This is  more important .", 
            "title": "Emphasis and Strong Emphasis"
        }, 
        {
            "location": "/slamdown-reference/#links", 
            "text": "Links contain the link title in square brackets ( [] ) and the link destination in\nparentheses ( () ).  [SlamData](http://slamdata.com)  results in:  SlamData  If the link title and destination are the same, you can use an autolink, where the URI\nis contained in angle brackets ( ).  http://slamdata.com   results in:  http://slamdata.com", 
            "title": "Links"
        }, 
        {
            "location": "/slamdown-reference/#images", 
            "text": "Images start with an explanation mark ( ! ), followed by the image description in square brackets\n( [] ) and the image URI in parentheses ( () ).  ![SlamData Logo](https://media.licdn.com/media/p/6/005/088/002/039b9f8.png)  results in:", 
            "title": "Images"
        }, 
        {
            "location": "/slamdown-reference/#inline-code-formatting", 
            "text": "To add code formatting (literal content with monospace font) inline, put the content between\nbacktick (`) characters.  Start SQL statements with `SELECT * FROM`  results in:  Start SQL statements with  SELECT * FROM", 
            "title": "Inline code formatting"
        }, 
        {
            "location": "/slamdown-reference/#evaluated-sql-query", 
            "text": "SlamDown extends CommonMark by allowing you to evaluate a SQL query and insert\nthe results into the rendered content. Start the query with an exclamation point\nand then contain the SQL query between double backtick (`) characters.  Note:   Notice how the path to the query below has a space between the backtick that\nends the path and the double backticks that end the query.  This is a necessary\nspace because three backticks in a row start a Fenced Code Block as stated above.   In the example below, if there are 20 documents in the  /col  file, then  There are !``SELECT COUNT(*) FROM `/col` `` documents inside the collection.  results in:  There are  20  documents inside the collection.", 
            "title": "Evaluated SQL Query"
        }, 
        {
            "location": "/slamdown-reference/#form-elements", 
            "text": "SlamDown contains a significant addition to CommonMark, which are form elements.\nThis allows for the creation of interactive reports.", 
            "title": "Form Elements"
        }, 
        {
            "location": "/slamdown-reference/#text-field", 
            "text": "Use one or more underscores ( _ ) to create a text input field where a user\ncan add text.  For example, this line creates an input file for a name. You can then refer to the user value with the string variable name  name .  name = ________  Optionally, you can pre-fill the input field with a default value by having\nit after the underscores in parentheses.\nThis line creates an input file for spouse name with a default value of\n\"none\". You can then refer to the user value with the string variable name  spouse .  spouse = ________ (none)  By default input fields are evaluated as String types.  To enforce a numeric type\nprefix the underscores with the ( # ) symbol.  For example:  year = #________", 
            "title": "Text Field"
        }, 
        {
            "location": "/slamdown-reference/#radio-buttons", 
            "text": "Use parentheses followed by text to indicate radio buttons. A set of radio buttons has\nonly one button selected at a time. Indicate which button is selected by putting an  x \nin the parentheses.  For example, this line creates a set of radio buttons with the values \"car\", \"bus\",\nand \"bike\", where \"car\" is marked as the default. The result is stored in the string\nvariable named  commute  for later use.  commute = (x) car () bus () bike  This results in:   Note:  Currently, the default value must be the first value.", 
            "title": "Radio Buttons"
        }, 
        {
            "location": "/slamdown-reference/#checkboxes", 
            "text": "Use square brackets followed by text to indicate checkboxes. In a set of checkboxes,\neach checkbox operates independently. Use an  x  in the square brackets to indicate\nthat the checkbox should be checked by default.\nThe string value returned will be an array of strings in square brackets.  For example, this line creates a set of checkboxes with the values \"Android\", \"iPhone\",\nand \"Blackberry\". The result is stored in the string variable named  phones  for later use.  phones = [] Android [x] iPhone [x] Blackberry  If left as the default, the  phones  variable will have the value:  ['iPhone', 'Blackberry'] .  This results in:", 
            "title": "Checkboxes"
        }, 
        {
            "location": "/slamdown-reference/#dropdown", 
            "text": "Use a comma-separated list in curly brackets to indicate a dropdown element.  For example, this line creates a dropdown element with BOS, SFO, and NYC entries.  The result is stored in the string variable named  city  for later use.  city = {BOS, SFO, NYC}  Optionally, include a default value by listing it in parentheses at the end.\nIn this line, NYC is set as the default.  city = {BOS, SFO, NYC} (NYC)  This results in:", 
            "title": "Dropdown"
        }, 
        {
            "location": "/slamdown-reference/#dates-and-times", 
            "text": "Provide a date, time or both date   time selector for users by implementing the following syntax.", 
            "title": "Dates and Times"
        }, 
        {
            "location": "/slamdown-reference/#date", 
            "text": "For example the following line creates a date selector element and stores the value in a variable called  start :  start = __ - __ - ____ (04-19-2016)", 
            "title": "Date"
        }, 
        {
            "location": "/slamdown-reference/#time", 
            "text": "The following lines creates a time selector element:  start = __ : __ (12:30 PM)", 
            "title": "Time"
        }, 
        {
            "location": "/slamdown-reference/#date-time", 
            "text": "The following line creates both a date and time selector element:  start = __ - __ - ____ __ : __ (06-06-2015 12:00 PM)  This results in:", 
            "title": "Date &amp; Time"
        }, 
        {
            "location": "/api-reference/", 
            "text": "SlamData API Reference\n\n\n\n\n \n\n\nIntroduction\n\n\nThis API Reference provides detailed information for developers to use when interacting with SlamData via the API.\n\n\n\n\n \n\n\nAssumptions\n\n\nThroughout this document examples of URLs might be given.  These examples assume that SlamData is running locally on IP 127.0.0.1 with hostname \nlocalhost\n and running on the default port \n20223\n\n\n\n\n \n\n\nExecuting a Small Query\n\n\nExecutes a SQL\n2\n query where the results and computation are expected to be relatively small. Pagination and some filtering are supported.\n\n\nURL\n\n\n/query/fs/{path}\n\n\n\n\nwhere \n{path}\n is an optional path to the data. If included, then all paths used in the query are relative to the \n{path}\n parameter, unless they begin with a \n/\n.  A complete URL would appear as follows:\n\n\nhttp://127.0.0.1:20223/query/fs/{path}\n\n\nMethod\n\n\nGET\n\n\nQuery parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\nRequired\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\nq\n\n\nThe SQL query\n\n\nRequired\n\n\n\n\n\n\n\n\noffset\n\n\nThe starting index of the results to return\n\n\nOptional\n\n\n0\n\n\n\n\n\n\nlimit\n\n\nThe number of results to return\n\n\nOptional\n\n\nAll results\n\n\n\n\n\n\nvar\n\n\nSpecifies variables in the query. See Note below.\n\n\nOptional\n\n\nNone\n\n\n\n\n\n\n\n\nNote:\n The \nvar\n parameter takes the format:\n\n\nvar.{name}={value}\n\n\n\n\nwhere \n{name}\n is the name of the variable and \n{value}\n is the value of the variable. For example, the query might contain the variable \ncutoff\n:\n\n\nSELECT * WHERE pop \n :cutoff\n\n\n\n\nThen the \ncutoff\n variable is assigned a value in the parameter \nvar.cutoff-1000\n.\n\n\nFailure to specify valid values for all variables used inside a query will result in an error. These values use the same syntax as the query itself; notably, strings should be surrounded by single quotes. Some acceptable values are \n123\n, \n\"CO\"\n, and \nDATE(\"2015-07-06\")\n.\n\n\nHeaders\n\n\n\n\n\n\n\n\nHeader\n\n\nDescription\n\n\nRequired\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\nAccept\n\n\nSpecifies the format of the response body.\n\n\nOptional\n\n\napplication/ldjson;mode=precise\n\n\n\n\n\n\nAccept-Encoding\n\n\nUse the value \ngzip\n to compress the output.\n\n\nOptional\n\n\nNo compression\n\n\n\n\n\n\n\n\nThe following values are supported for the \nAccept\n header:\n\n\n\n\n\n\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNone\n\n\n\"Human-Readable\" results, one result per line. Note: not parseable as a single JSON object.\n\n\n\n\n\n\napplication/json\n\n\nNicely formatted JSON array\n\n\n\n\n\n\napplication/ldjson;mode=precise\n\n\nOne result per line\n\n\n\n\n\n\ntext/csv\n\n\nComma-separated results. See Note below.\n\n\n\n\n\n\n\n\nNote:\n The formatting of CSV output can be controlled with an extended media type with parameters for \ncolumnDelimeter\n, \nquoteChar\n and \nescapeChar\n. For example:\n\n\nAccept: text/csv; columnDelimiter=\n|\nrowDelimiter=\n;\nquoteChar=\n'\nescapeChar=\n\\\n.\n\n\n\n\nExample\n\n\nThe following example returns data for the query:\n\n\nSELECT * from \n//data/SampleJSON\n WHERE state='WA'\n\n\n\n\nNote\n:\n\n\n\n\nThe URL must be encoded: spaces as %20 and the quotes as %22, etc. The URL below does not show this.\n\n\n\n\nRequest\n\n\nGET http://localhost:20223/query/fs?q=SELECT * from `//data/SampleJSON` WHERE state=\nWA\n\n\nHeaders:\n  Accept: application/json\n\n\n\n\nResponse\n\n\n[\n  {\n    \ncity\n: \nALGONA\n,\n    \nstate\n: \nWA\n,\n    \npop\n: 22846,\n    \nloc\n: [\n      -122.270057,\n      47.316339\n    ]\n  },\n  {\n    \ncity\n: \nAUBURN\n,\n    \nstate\n: \nWA\n,\n    \npop\n: 22846,\n    \nloc\n: [\n      -122.206741,\n      47.30503\n    ]\n  },\n  ...\n]\n\n\n\n\n\n\n \n\n\nExecuting a Large Query\n\n\nExecutes a SQL\u00b2 query where the results or computation are expected to be relatively large. The results are stored in an output path that is specified in the \nDestination\n header. Pagination and some filtering are supported.\n\n\nURL\n\n\n/query/fs/{path}\n\n\n\n\nwhere \n{path}\n is an optional path to the data. If included, then all paths used in the query and the output path are relative to the \n{path}\n parameter, unless they begin with a \n/\n.\n\n\nMethod\n\n\nPOST\n\n\nQuery parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\nRequired\n\n\nDefault\n\n\nMethod\n\n\n\n\n\n\n\n\n\n\noffset\n\n\nThe starting index of the results to return\n\n\n0\n\n\nOptional\n\n\nGET\n\n\n\n\n\n\nlimit\n\n\nThe number of results to return\n\n\nAll results\n\n\nGET\n\n\n\n\n\n\n\n\nvar\n\n\nSpecifies variables in the query. See Note below.\n\n\nOptional\n\n\nNone\n\n\nGET and POST\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\nThe \nvar\n parameter takes the format:\n\n\n\n\nvar.{name}={value}\n\n\n\n\nwhere \n{name}\n is the name of the variable and \n{value}\n is the value of the variable. For example, the query might contain the variable \ncutoff\n:\n\n\nSELECT * WHERE pop \n :cutoff\n\n\n\n\nThen the \ncutoff\n variable is assigned a value in the parameter \nvar.cutoff=1000\n.\n\n\nFailure to specify valid values for all variables used inside a query will result in an error. These values use the same syntax as the query itself; notably, strings should be surrounded by single quotes. Some acceptable values are \n123\n, \n\"CO\"\n, and \nDATE(\"2015-07-06\")\n.\n\n\nPOST body\n\n\nThe POST body contains the query.\n\n\nHeaders\n\n\n\n\n\n\n\n\nHeader\n\n\nDescription\n\n\nRequired\n\n\n\n\n\n\n\n\n\n\nDestination\n\n\nThe URL of the output path, where the results of the query will become available if this API successfully completes.\n\n\nRequired\n\n\n\n\n\n\n\n\nResponse\n\n\nThe following response elements are returned in JSON format:\n\n\n\n\n\n\n\n\nElement\n\n\nDescription\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nout\n\n\nPath to the query results\n\n\nElement returned if request is successful\n\n\n\n\n\n\nerror\n\n\nError text\n\n\nElement is returned if request is not successful\n\n\n\n\n\n\nphases\n\n\nAn array containing a sequence of objects containing the result from each phase of the query compilation process\n\n\nSee note below\n\n\n\n\n\n\n\n\nNote:\n\n\n\n\nPhase objects have three possible forms. All phase objects have a \"name\" element with the phase name.\n\n\n\n\nA phase may contain a \ntree\n element with \ntype\n, \nlabel\n and optional \nchildren\n elements, such as:\n\n\n{\n  ...,\n  \nphases\n: [\n    ...,\n    {\n      \nname\n: \nLogical Plan\n,\n      \ntree\n: {\n        \ntype\n: \nLogicalPlan/Let\n,\n        \nlabel\n: \n'tmp0\n,\n        \nchildren\n: [\n          {\n            \ntype\n: \nLogicalPlan/Read\n,\n            \nlabel\n: \n./zips\n\n          },\n          ...\n        ]\n      }\n    },\n    ...\n  ]\n}\n\n\n\n\nOr a phase may contain a \ndetail\n element with some kind of text, such as:\n\n\n{\n  ...,\n  \nphases\n: [\n    ...,\n    {\n      \nname\n: \nMongo\n,\n      \ndetail\n: \ndb.zips.aggregate([ { \n$sort\n : { \npop\n : 1}}])\n\n    }\n  ]\n}\n\n\n\n\nIf an error occurs, then the phase contains an \nerror\n element with the error message. Typically the error phase is the last phase in the array. For example:\n\n\n{\n  ...,\n  \nphases\n: [\n    ...,\n    {\n      \nname\n: \nPhysical Plan\n,\n      \nerror\n: \nCannot compile ...\n\n    }\n  ]\n}\n\n\n\n\nNote:\n\n\n\n\nThe error is also included at the top level of the response, as described in the elements table.\n\n\n\n\nExample\n\n\nThe following example returns data for the query:\n\n\nSELECT * from `/data/SampleJSON` WHERE state=\nWA\n\n\n\n\n\nIt puts the result in a new file called \nSampleResult\n in the path \n/data\n.\n\n\nRequest\n\n\nPOST http://localhost:20223/query/fs\n\nPOST body:\n  SELECT * FROM `/data/SampleJSON` WHERE state=\nWA\n\n\nHeaders:\n  Destination: /data/sampleResults\n  Accept: application/json\n\n\n\n\nResponse\n\n\n{\n  \nout\n: \n/data/sampleResults\n,\n  \nphases\n: [\n    {\n      \nname\n: \nSQL AST\n,\n      \ntree\n: {\n        \ntype\n: \nAST/Select\n,\n        \nlabel\n: null,\n        \nchildren\n: [\n          {\n            \ntype\n: \nAST/Proj\n,\n            \nlabel\n: null,\n            \nchildren\n: [\n              {\n                \ntype\n: \nAST/Splice\n,\n                \nlabel\n: null\n              }\n            ]\n          },\n          ...\n        ]\n      }\n    },\n    ...\n  ]\n}\n\n\n\n\n\n\n \n\n\nCompiling a Query\n\n\nCompiles, but does not execute a SQL\n2\n query.\n\n\nURL\n\n\n/compile/fs/{path}\n\n\n\n\nwhere \n{path}\n is an optional path to the data. If included, then all paths used in the query are relative to the \n{path}\n parameter, unless they begin with a \n/\n.\n\n\nThe GET method has the SQL\u00b2 query as a query parameter and the POST method has the SQL\u00b2 query in the POST body.\n\n\nMethod\n\n\nGET\n or \nPOST\n\n\nQuery parameters\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\nRequired\n\n\nDefault\n\n\nMethod\n\n\n\n\n\n\n\n\n\n\nq\n\n\nThe SQL query\n\n\nRequired\n\n\n\n\nGET only\n\n\n\n\n\n\nvar\n\n\nSpecifies variables in the query. See Note below.\n\n\nOptional\n\n\nNone\n\n\nGET and POST\n\n\n\n\n\n\n\n\nNote:\n \n\n\n\n\nThe \nvar\n parameter takes the format:\n\n\n\n\nvar.{name}={value}\n\n\n\n\nwhere \n{name}\n is the name of the variable and \n{value}\n is the value of the variable. For example, the query might contain the variable \ncutoff\n:\n\n\nSELECT * WHERE pop \n :cutoff\n\n\n\n\nThen the \ncutoff\n variable is assigned a value in the parameter \nvar.cutoff=1000\n.\n\n\nFailure to specify valid values for all variables used inside a query will result in an error. These values use the same syntax as the query itself; notably, strings should be surrounded by single quotes. Some acceptable values are \n123\n, \n\"CO\"\n, and \nDATE(\"2015-07-06\")\n.\n\n\nPOST body\n\n\nFor the POST request, use the SQL query as the POST body.\n\n\nResponse\n\n\nIf the query compiles successfully, then the query plan is returned. If an error occurs, then JSON with an \"error\" element with message is returned, such as:\n\n\n{\n  \nerror\n: \noperator ';' expected; ErrorToken(unclosed string literal)\n\n}\n\n\n\n\nExample\n\n\nThe following example returns the plan for the query:\n\n\nSELECT * FROM `/data/SampleJSON` WHERE state=\nWA\n\n\n\n\n\nNote that you may need to encode the spaces as %20 and the quotes as %22.\n\n\nRequest\n\n\nGET http://localhost:20223/compile/fs?q=SELECT * FROM `/data/SampleJSON` WHERE state=\nWA\n\n\n\n\n\nResponse\n\n\nMongo\ndb.getCollection(\nSampleJSON\n).aggregate(\n  [{ \n$match\n: { \nstate\n: \nWA\n } }, { \n$out\n: \ntmp.gen_0\n }],\n  { \nallowDiskUse\n: true });\ndb.tmp.gen_0.find();\n\n\n\n\n\n\n \n\n\nRetrieving Data\n\n\nRetrieves data from the specified path. Pagination is supported.\n\n\nURL\n\n\n/data/fs/{path}\n\n\n\n\nwhere \n{path}\n is a path to the data to retreive.\n\n\nMethod\n\n\nGET\n\n\nHeaders\n\n\n\n\n\n\n\n\nHeader\n\n\nDescription\n\n\nRequired\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\nAccept\n\n\nSpecifies the format of the response body.\n\n\nOptional\n\n\napplication/ldjson;mode=precise\n\n\n\n\n\n\nAccept-Encoding\n\n\nUse the value \ngzip\n to compress the output.\n\n\nOptional\n\n\nNo compression\n\n\n\n\n\n\n\n\nThe following values are supported for the \nAccept\n header:\n\n\n\n\n\n\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNone\n\n\n\"Human-Readable\" results, one result per line. Note: not parseable as a single JSON object.\n\n\n\n\n\n\napplication/json\n\n\nNicely formatted JSON array\n\n\n\n\n\n\napplication/ldjson;mode=precise\n\n\n[Precise JSON]{#precise-json}, one result per line\n\n\n\n\n\n\ntext/csv\n\n\nComma-separated results. See Note below.\n\n\n\n\n\n\n\n\nExample\n\n\nThe following example returns data at the path \n/data/SampleJSON\n. Data for the 10th and 11th items are returned.\n\n\nRequest\n\n\nGET http://localhost:20223/data/fs/data/SampleJSON?offset=10\nlimit=2\n\nHeaders:\n  Accept: application/json\n\n\n\n\nResponse\n\n\n[\n  {\n    \ncity\n: \nWESTOVER AFB\n,\n    \nstate\n: \nMA\n,\n    \npop\n: 1764,\n    \nloc\n: [\n      -72.558657,\n      42.196672\n    ]\n  },\n  {\n    \ncity\n: \nCUMMINGTON\n,\n    \nstate\n: \nMA\n,\n    \npop\n: 1484,\n    \nloc\n: [\n      -72.905767,\n      42.435296\n    ]\n  }\n]\n\n\n\n\nNote\n:\n\n\n\n\nIf you remove the \nAccept\n header, then you will receive Precise JSON, which is the default format. The response would then look like this:\n\n\n\n\n{ \ncity\n: \nWESTOVER AFB\n, \nstate\n: \nMA\n, \npop\n: 1764, \nloc\n: [ -72.558657, 42.196672 ] }\n{ \ncity\n: \nCUMMINGTON\n, \nstate\n: \nMA\n, \npop\n: 1484, \nloc\n: [ -72.905767, 42.435296 ] }\n\n\n\n\n\n\n \n\n\nReplacing Data\n\n\nReplaces data from the specified path.\n\n\nData is placed in the PUT body in the format of one JSON object per line. If successful, it replaces the existing data with the new data. If unsuccessful, it returns an error and the existing data is unchanged.\n\n\nNote:\n\n\n\n\nAn error will be returned if the path is a path to a view rather than a file.\n\n\n\n\nURL\n\n\n/data/fs/{path}\n\n\n\n\nwhere \n{path}\n is a path to the data to replace.\n\n\nMethod\n\n\nPUT\n\n\nHeaders\n\n\n\n\n\n\n\n\nHeader\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nContent-Type\n\n\nSpecifies the format of the PUT body. Set to \napplication/ldjson;mode=precise\n\n\n\n\n\n\n\n\nPUT body\n\n\nThe data to replace, one JSON object per line.\n\n\nExample\n\n\nThe following example replaces the data at the path \n/data/SampleJSON\n with two items.\n\n\nRequest\n\n\nPUT http://localhost:20223/data/fs/data/SampleJSON\n\nHeaders:\n  Content-Type: application/ldjson;mode=precise\n\n\n\n\nResponse\n\n\nStatus code 200 if successful. No response body.\n\n\nIf unsuccessful, then JSON is returned with two elements: \nerror\n, which contains a short description of the error, and \ndetail\n, which contains more detailed information. For example:\n\n\n{\n  \nerror\n: \nsome uploaded value(s) could not be processed\n,\n  \ndetails\n: [\n    {\n      \ndetail\n: \nJSON contains invalid suffix content: , value: Str(parse error: { \\\ncity\\\n: \\\nNEVERLAND\\\n, \\\nstate\\\n: \\\nZZ\\\n, \\\npop\\\n: 2354, \\\nloc\\\n: [ -73.658, 41.443 ] },)\n\n    }\n  ]\n}\n\n\n\n\n\n\n \n\n\nAppending Data\n\n\nAppends data at the specified path.\n\n\nData is placed in the POST body in the format of one JSON object per line. If successful, it appends the existing data with the new data. If unsuccessful, it returns an error and the existing data is unchanged.\n\n\nNote:\n\n\n\n\nAn error will be returned if the path is a path to a view rather than a file.\n\n\n\n\nURL\n\n\n/data/fs/{path}\n\n\n\n\nwhere \n{path}\n is a path to the data to be appended.\n\n\nMethod\n\n\nPOST\n\n\nHeaders\n\n\n\n\n\n\n\n\nHeader\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nContent-Type\n\n\nSpecifies the format of the PUT body. Set to \napplication/ldjson;mode=precise\n\n\n\n\n\n\n\n\nExample\n\n\nThe following example appends one item to the data at the path \n/data/SampleJSON\n.\n\n\nRequest\n\n\nPOST http://localhost:20223/data/fs/data/SampleJSON\n\nHeaders:\n  Content-Type: application/ldjson;mode=precise\n\n\n\n\nResponse\n\n\nStatus code 200 if successful. No response body.\n\n\nIf unsuccessful, then JSON is returned with two elements: \nerror\n, which contains a short description of the error, and \ndetail\n, which contains more detailed information. For example:\n\n\n{\n  \nerror\n: \nsome uploaded value(s) could not be processed\n,\n  \ndetails\n: [\n    {\n      \ndetail\n: \nJSON contains invalid suffix content: ,; value: Str(parse error: { \\\ncity\\\n: \\\nUTOPIA\\\n, \\\nstate\\\n: \\\nZZ\\\n, \\\npop\\\n: 2354, \\\nloc\\\n: [ -75.757, 40.941 ] },)\n\n    }\n  ]\n}\n\n\n\n\n\n\n \n\n\nDeleting Data\n\n\nRemoves all data at the specified path.\n\n\nNote:\n\n\n\n\nAn error will be returned if the path is a path to a view rather than a file. Views may be added or deleted using the \n/mount\n API requests.\n\n\nSingle files are deleted atomically, meaning that the equivalent MongoDB collection is removed, rather than a collection's documents being removed individually until the collection is empty.\n\n\n\n\nURL\n\n\n/data/fs/{path}\n\n\n\n\nwhere \n{path}\n is a path to the data to be deleted.\n\n\nMethod\n\n\nDELETE\n\n\nExample\n\n\nThe following example deletes all data at the path \n/data/SampleJSON\n.\n\n\nRequest\n\n\nDELETE http://localhost:20223/data/fs/data/SampleJSON\n\n\n\n\nResponse\n\n\nStatus code 200 if successful. No response body.\n\n\nIf unsuccessful, then JSON is returned with two elements: \nerror\n, which contains a short description of the error, and optionally \ndetail\n, which contains more detailed information. For example:\n\n\n{\n  \nerror\n: \n./BadPath: doesn't exist\n\n}\n\n\n\n\n\n\n \n\n\nMoving Data\n\n\nMoves data from one path to another. The origin path is specified in the URL and the desitnation path is specified in the \nDestination\n header. Single files are moved atomically.\n\n\nNote:\n\n\n\n\nAn error will be returned if either the origin or destination path is a path to a view rather than a file. Views may be moved using the \n/mount\n API requests.\n\n\nSingle files are moved atomically, meaning that the equivalent MongoDB collection is moved, rather than a collection's documents being moved individually.\n\n\n\n\nURL\n\n\n/data/fs/{path}\n\n\n\n\nwhere \n{path}\n is a path to the data to be moved.\n\n\nMethod\n\n\nMOVE\n\n\nHeaders\n\n\n\n\n\n\n\n\nHeader\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nDestination\n\n\nPath to the new location of the data\n\n\n\n\n\n\n\n\nExample\n\n\nThe following example moves all data at the path \n/data/SampleJSON\n to \n/data/SampleJSON2\n.\n\n\nRequest\n\n\nMOVE http://localhost:20223/data/fs/data/SampleJSON\n\nHeaders:\n  Destination: /data/SampleJSON2\n\n\n\n\nResponse\n\n\nStatus code 200 if successful. No response body.\n\n\n\n\n \n\n\nRetrieving a Mount\n\n\nRetrieves the configuration for the mount point at the specified path.\n\n\nURL\n\n\n/mount/fs/{path}/\n\n\n\n\nwhere \n{path}\n is a path for the mount to retrieve.\n\n\nNote:\n Be sure to end with a slash.\n\n\nMethod\n\n\nGET\n\n\nExample\n\n\nThe following example returns mount at the path \n/\n.\n\n\nRequest\n\n\nGET http://localhost:20223/mount/fs/\n\n\n\n\nResponse\n\n\n{\n  \nmongodb\n:\n  {\n    \nconnectionUri\n:\nmongodb://myusername:mypassword@myserver.example.com:20223/data\n\n  }\n}\n\n\n\n\n\n\n \n\n\nDeleting a Mount\n\n\nDeletes the MongoDB mount point at the specified path.\n\n\nIf there is no mount at the specified path, the request succeeds, but with no response.\n\n\nURL\n\n\n/mount/fs/{path}/\n\n\n\n\nwhere \n{path}\n is a path for the mount to delete.\n\n\nNote:\n\n\n\n\nBe sure to end with a slash.\n\n\n\n\nMethod\n\n\nDELETE\n\n\nResponse\n\n\nReturns the text \"\ndeleted {path}\n\", where \n{path}\n is the path to the deleted mount.\n\n\nExample\n\n\nThe following example deletes mount at the path \n/\n.\n\n\nRequest\n\n\nDELETE http://localhost:20223/mount/fs/\n\n\n\n\nResponse\n\n\ndeleted /\n\n\n\n\n\n\n \n\n\nChanging the Port\n\n\nShuts down the running instance and restarts the server on the specified port.\n\n\nThe port is specified in the PUT body.\n\n\nURL\n\n\n/server/port\n\n\n\n\nMethod\n\n\nPUT\n\n\nResponse\n\n\nReturns the text \"\nchanged port to {port-number}\n\", where \n{port-number}\n is the new port number.\n\n\nExample\n\n\nThe following example changes the port number from 20223 to 20224.\n\n\nRequest\n\n\nPUT http://localhost:20223/server/port\n\nPUT body:\n  20224\n\n\n\n\nResponse\n\n\nchanged port to 20224\n\n\n\n\n \n\n\nSetting the Port to the Default Value\n\n\nShuts down the running instance and restarts the server on the default port, which is 20223.\n\n\nURL\n\n\n/server/port\n\n\n\n\nMethod\n\n\nDELETE\n\n\nResponse\n\n\nNone\n\n\nExample\n\n\nThe following example sets the port number from 20224 back to the default.\n\n\nRequest\n\n\nDELETE http://localhost:20224/server/port", 
            "title": "Reference (API)"
        }, 
        {
            "location": "/api-reference/#slamdata-api-reference", 
            "text": "", 
            "title": "SlamData API Reference"
        }, 
        {
            "location": "/api-reference/#introduction", 
            "text": "This API Reference provides detailed information for developers to use when interacting with SlamData via the API.", 
            "title": "Introduction"
        }, 
        {
            "location": "/api-reference/#assumptions", 
            "text": "Throughout this document examples of URLs might be given.  These examples assume that SlamData is running locally on IP 127.0.0.1 with hostname  localhost  and running on the default port  20223", 
            "title": "Assumptions"
        }, 
        {
            "location": "/api-reference/#executing-a-small-query", 
            "text": "Executes a SQL 2  query where the results and computation are expected to be relatively small. Pagination and some filtering are supported.", 
            "title": "Executing a Small Query"
        }, 
        {
            "location": "/api-reference/#url", 
            "text": "/query/fs/{path}  where  {path}  is an optional path to the data. If included, then all paths used in the query are relative to the  {path}  parameter, unless they begin with a  / .  A complete URL would appear as follows:  http://127.0.0.1:20223/query/fs/{path}", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method", 
            "text": "GET", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#query-parameters", 
            "text": "Parameter  Description  Required  Default      q  The SQL query  Required     offset  The starting index of the results to return  Optional  0    limit  The number of results to return  Optional  All results    var  Specifies variables in the query. See Note below.  Optional  None     Note:  The  var  parameter takes the format:  var.{name}={value}  where  {name}  is the name of the variable and  {value}  is the value of the variable. For example, the query might contain the variable  cutoff :  SELECT * WHERE pop   :cutoff  Then the  cutoff  variable is assigned a value in the parameter  var.cutoff-1000 .  Failure to specify valid values for all variables used inside a query will result in an error. These values use the same syntax as the query itself; notably, strings should be surrounded by single quotes. Some acceptable values are  123 ,  \"CO\" , and  DATE(\"2015-07-06\") .", 
            "title": "Query parameters"
        }, 
        {
            "location": "/api-reference/#headers", 
            "text": "Header  Description  Required  Default      Accept  Specifies the format of the response body.  Optional  application/ldjson;mode=precise    Accept-Encoding  Use the value  gzip  to compress the output.  Optional  No compression     The following values are supported for the  Accept  header:     Value  Description      None  \"Human-Readable\" results, one result per line. Note: not parseable as a single JSON object.    application/json  Nicely formatted JSON array    application/ldjson;mode=precise  One result per line    text/csv  Comma-separated results. See Note below.     Note:  The formatting of CSV output can be controlled with an extended media type with parameters for  columnDelimeter ,  quoteChar  and  escapeChar . For example:  Accept: text/csv; columnDelimiter= | rowDelimiter= ; quoteChar= ' escapeChar= \\ .", 
            "title": "Headers"
        }, 
        {
            "location": "/api-reference/#example", 
            "text": "The following example returns data for the query:  SELECT * from  //data/SampleJSON  WHERE state='WA'  Note :   The URL must be encoded: spaces as %20 and the quotes as %22, etc. The URL below does not show this.", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request", 
            "text": "GET http://localhost:20223/query/fs?q=SELECT * from `//data/SampleJSON` WHERE state= WA \n\nHeaders:\n  Accept: application/json", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response", 
            "text": "[\n  {\n     city :  ALGONA ,\n     state :  WA ,\n     pop : 22846,\n     loc : [\n      -122.270057,\n      47.316339\n    ]\n  },\n  {\n     city :  AUBURN ,\n     state :  WA ,\n     pop : 22846,\n     loc : [\n      -122.206741,\n      47.30503\n    ]\n  },\n  ...\n]", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#executing-a-large-query", 
            "text": "Executes a SQL\u00b2 query where the results or computation are expected to be relatively large. The results are stored in an output path that is specified in the  Destination  header. Pagination and some filtering are supported.", 
            "title": "Executing a Large Query"
        }, 
        {
            "location": "/api-reference/#url_1", 
            "text": "/query/fs/{path}  where  {path}  is an optional path to the data. If included, then all paths used in the query and the output path are relative to the  {path}  parameter, unless they begin with a  / .", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_1", 
            "text": "POST", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#query-parameters_1", 
            "text": "Parameter  Description  Required  Default  Method      offset  The starting index of the results to return  0  Optional  GET    limit  The number of results to return  All results  GET     var  Specifies variables in the query. See Note below.  Optional  None  GET and POST     Note:   The  var  parameter takes the format:   var.{name}={value}  where  {name}  is the name of the variable and  {value}  is the value of the variable. For example, the query might contain the variable  cutoff :  SELECT * WHERE pop   :cutoff  Then the  cutoff  variable is assigned a value in the parameter  var.cutoff=1000 .  Failure to specify valid values for all variables used inside a query will result in an error. These values use the same syntax as the query itself; notably, strings should be surrounded by single quotes. Some acceptable values are  123 ,  \"CO\" , and  DATE(\"2015-07-06\") .", 
            "title": "Query parameters"
        }, 
        {
            "location": "/api-reference/#post-body", 
            "text": "The POST body contains the query.", 
            "title": "POST body"
        }, 
        {
            "location": "/api-reference/#headers_1", 
            "text": "Header  Description  Required      Destination  The URL of the output path, where the results of the query will become available if this API successfully completes.  Required", 
            "title": "Headers"
        }, 
        {
            "location": "/api-reference/#response_1", 
            "text": "The following response elements are returned in JSON format:     Element  Description  Notes      out  Path to the query results  Element returned if request is successful    error  Error text  Element is returned if request is not successful    phases  An array containing a sequence of objects containing the result from each phase of the query compilation process  See note below     Note:   Phase objects have three possible forms. All phase objects have a \"name\" element with the phase name.   A phase may contain a  tree  element with  type ,  label  and optional  children  elements, such as:  {\n  ...,\n   phases : [\n    ...,\n    {\n       name :  Logical Plan ,\n       tree : {\n         type :  LogicalPlan/Let ,\n         label :  'tmp0 ,\n         children : [\n          {\n             type :  LogicalPlan/Read ,\n             label :  ./zips \n          },\n          ...\n        ]\n      }\n    },\n    ...\n  ]\n}  Or a phase may contain a  detail  element with some kind of text, such as:  {\n  ...,\n   phases : [\n    ...,\n    {\n       name :  Mongo ,\n       detail :  db.zips.aggregate([ {  $sort  : {  pop  : 1}}]) \n    }\n  ]\n}  If an error occurs, then the phase contains an  error  element with the error message. Typically the error phase is the last phase in the array. For example:  {\n  ...,\n   phases : [\n    ...,\n    {\n       name :  Physical Plan ,\n       error :  Cannot compile ... \n    }\n  ]\n}  Note:   The error is also included at the top level of the response, as described in the elements table.", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#example_1", 
            "text": "The following example returns data for the query:  SELECT * from `/data/SampleJSON` WHERE state= WA   It puts the result in a new file called  SampleResult  in the path  /data .", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_1", 
            "text": "POST http://localhost:20223/query/fs\n\nPOST body:\n  SELECT * FROM `/data/SampleJSON` WHERE state= WA \n\nHeaders:\n  Destination: /data/sampleResults\n  Accept: application/json", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_2", 
            "text": "{\n   out :  /data/sampleResults ,\n   phases : [\n    {\n       name :  SQL AST ,\n       tree : {\n         type :  AST/Select ,\n         label : null,\n         children : [\n          {\n             type :  AST/Proj ,\n             label : null,\n             children : [\n              {\n                 type :  AST/Splice ,\n                 label : null\n              }\n            ]\n          },\n          ...\n        ]\n      }\n    },\n    ...\n  ]\n}", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#compiling-a-query", 
            "text": "Compiles, but does not execute a SQL 2  query.", 
            "title": "Compiling a Query"
        }, 
        {
            "location": "/api-reference/#url_2", 
            "text": "/compile/fs/{path}  where  {path}  is an optional path to the data. If included, then all paths used in the query are relative to the  {path}  parameter, unless they begin with a  / .  The GET method has the SQL\u00b2 query as a query parameter and the POST method has the SQL\u00b2 query in the POST body.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_2", 
            "text": "GET  or  POST", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#query-parameters_2", 
            "text": "Parameter  Description  Required  Default  Method      q  The SQL query  Required   GET only    var  Specifies variables in the query. See Note below.  Optional  None  GET and POST     Note:     The  var  parameter takes the format:   var.{name}={value}  where  {name}  is the name of the variable and  {value}  is the value of the variable. For example, the query might contain the variable  cutoff :  SELECT * WHERE pop   :cutoff  Then the  cutoff  variable is assigned a value in the parameter  var.cutoff=1000 .  Failure to specify valid values for all variables used inside a query will result in an error. These values use the same syntax as the query itself; notably, strings should be surrounded by single quotes. Some acceptable values are  123 ,  \"CO\" , and  DATE(\"2015-07-06\") .", 
            "title": "Query parameters"
        }, 
        {
            "location": "/api-reference/#post-body_1", 
            "text": "For the POST request, use the SQL query as the POST body.", 
            "title": "POST body"
        }, 
        {
            "location": "/api-reference/#response_3", 
            "text": "If the query compiles successfully, then the query plan is returned. If an error occurs, then JSON with an \"error\" element with message is returned, such as:  {\n   error :  operator ';' expected; ErrorToken(unclosed string literal) \n}", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#example_2", 
            "text": "The following example returns the plan for the query:  SELECT * FROM `/data/SampleJSON` WHERE state= WA   Note that you may need to encode the spaces as %20 and the quotes as %22.", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_2", 
            "text": "GET http://localhost:20223/compile/fs?q=SELECT * FROM `/data/SampleJSON` WHERE state= WA", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_4", 
            "text": "Mongo\ndb.getCollection( SampleJSON ).aggregate(\n  [{  $match : {  state :  WA  } }, {  $out :  tmp.gen_0  }],\n  {  allowDiskUse : true });\ndb.tmp.gen_0.find();", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#retrieving-data", 
            "text": "Retrieves data from the specified path. Pagination is supported.", 
            "title": "Retrieving Data"
        }, 
        {
            "location": "/api-reference/#url_3", 
            "text": "/data/fs/{path}  where  {path}  is a path to the data to retreive.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_3", 
            "text": "GET", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#headers_2", 
            "text": "Header  Description  Required  Default      Accept  Specifies the format of the response body.  Optional  application/ldjson;mode=precise    Accept-Encoding  Use the value  gzip  to compress the output.  Optional  No compression     The following values are supported for the  Accept  header:     Value  Description      None  \"Human-Readable\" results, one result per line. Note: not parseable as a single JSON object.    application/json  Nicely formatted JSON array    application/ldjson;mode=precise  [Precise JSON]{#precise-json}, one result per line    text/csv  Comma-separated results. See Note below.", 
            "title": "Headers"
        }, 
        {
            "location": "/api-reference/#example_3", 
            "text": "The following example returns data at the path  /data/SampleJSON . Data for the 10th and 11th items are returned.", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_3", 
            "text": "GET http://localhost:20223/data/fs/data/SampleJSON?offset=10 limit=2\n\nHeaders:\n  Accept: application/json", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_5", 
            "text": "[\n  {\n     city :  WESTOVER AFB ,\n     state :  MA ,\n     pop : 1764,\n     loc : [\n      -72.558657,\n      42.196672\n    ]\n  },\n  {\n     city :  CUMMINGTON ,\n     state :  MA ,\n     pop : 1484,\n     loc : [\n      -72.905767,\n      42.435296\n    ]\n  }\n]  Note :   If you remove the  Accept  header, then you will receive Precise JSON, which is the default format. The response would then look like this:   {  city :  WESTOVER AFB ,  state :  MA ,  pop : 1764,  loc : [ -72.558657, 42.196672 ] }\n{  city :  CUMMINGTON ,  state :  MA ,  pop : 1484,  loc : [ -72.905767, 42.435296 ] }", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#replacing-data", 
            "text": "Replaces data from the specified path.  Data is placed in the PUT body in the format of one JSON object per line. If successful, it replaces the existing data with the new data. If unsuccessful, it returns an error and the existing data is unchanged.  Note:   An error will be returned if the path is a path to a view rather than a file.", 
            "title": "Replacing Data"
        }, 
        {
            "location": "/api-reference/#url_4", 
            "text": "/data/fs/{path}  where  {path}  is a path to the data to replace.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_4", 
            "text": "PUT", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#headers_3", 
            "text": "Header  Description      Content-Type  Specifies the format of the PUT body. Set to  application/ldjson;mode=precise", 
            "title": "Headers"
        }, 
        {
            "location": "/api-reference/#put-body", 
            "text": "The data to replace, one JSON object per line.", 
            "title": "PUT body"
        }, 
        {
            "location": "/api-reference/#example_4", 
            "text": "The following example replaces the data at the path  /data/SampleJSON  with two items.", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_4", 
            "text": "PUT http://localhost:20223/data/fs/data/SampleJSON\n\nHeaders:\n  Content-Type: application/ldjson;mode=precise", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_6", 
            "text": "Status code 200 if successful. No response body.  If unsuccessful, then JSON is returned with two elements:  error , which contains a short description of the error, and  detail , which contains more detailed information. For example:  {\n   error :  some uploaded value(s) could not be processed ,\n   details : [\n    {\n       detail :  JSON contains invalid suffix content: , value: Str(parse error: { \\ city\\ : \\ NEVERLAND\\ , \\ state\\ : \\ ZZ\\ , \\ pop\\ : 2354, \\ loc\\ : [ -73.658, 41.443 ] },) \n    }\n  ]\n}", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#appending-data", 
            "text": "Appends data at the specified path.  Data is placed in the POST body in the format of one JSON object per line. If successful, it appends the existing data with the new data. If unsuccessful, it returns an error and the existing data is unchanged.  Note:   An error will be returned if the path is a path to a view rather than a file.", 
            "title": "Appending Data"
        }, 
        {
            "location": "/api-reference/#url_5", 
            "text": "/data/fs/{path}  where  {path}  is a path to the data to be appended.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_5", 
            "text": "POST", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#headers_4", 
            "text": "Header  Description      Content-Type  Specifies the format of the PUT body. Set to  application/ldjson;mode=precise", 
            "title": "Headers"
        }, 
        {
            "location": "/api-reference/#example_5", 
            "text": "The following example appends one item to the data at the path  /data/SampleJSON .", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_5", 
            "text": "POST http://localhost:20223/data/fs/data/SampleJSON\n\nHeaders:\n  Content-Type: application/ldjson;mode=precise", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_7", 
            "text": "Status code 200 if successful. No response body.  If unsuccessful, then JSON is returned with two elements:  error , which contains a short description of the error, and  detail , which contains more detailed information. For example:  {\n   error :  some uploaded value(s) could not be processed ,\n   details : [\n    {\n       detail :  JSON contains invalid suffix content: ,; value: Str(parse error: { \\ city\\ : \\ UTOPIA\\ , \\ state\\ : \\ ZZ\\ , \\ pop\\ : 2354, \\ loc\\ : [ -75.757, 40.941 ] },) \n    }\n  ]\n}", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#deleting-data", 
            "text": "Removes all data at the specified path.  Note:   An error will be returned if the path is a path to a view rather than a file. Views may be added or deleted using the  /mount  API requests.  Single files are deleted atomically, meaning that the equivalent MongoDB collection is removed, rather than a collection's documents being removed individually until the collection is empty.", 
            "title": "Deleting Data"
        }, 
        {
            "location": "/api-reference/#url_6", 
            "text": "/data/fs/{path}  where  {path}  is a path to the data to be deleted.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_6", 
            "text": "DELETE", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#example_6", 
            "text": "The following example deletes all data at the path  /data/SampleJSON .", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_6", 
            "text": "DELETE http://localhost:20223/data/fs/data/SampleJSON", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_8", 
            "text": "Status code 200 if successful. No response body.  If unsuccessful, then JSON is returned with two elements:  error , which contains a short description of the error, and optionally  detail , which contains more detailed information. For example:  {\n   error :  ./BadPath: doesn't exist \n}", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#moving-data", 
            "text": "Moves data from one path to another. The origin path is specified in the URL and the desitnation path is specified in the  Destination  header. Single files are moved atomically.  Note:   An error will be returned if either the origin or destination path is a path to a view rather than a file. Views may be moved using the  /mount  API requests.  Single files are moved atomically, meaning that the equivalent MongoDB collection is moved, rather than a collection's documents being moved individually.", 
            "title": "Moving Data"
        }, 
        {
            "location": "/api-reference/#url_7", 
            "text": "/data/fs/{path}  where  {path}  is a path to the data to be moved.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_7", 
            "text": "MOVE", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#headers_5", 
            "text": "Header  Description      Destination  Path to the new location of the data", 
            "title": "Headers"
        }, 
        {
            "location": "/api-reference/#example_7", 
            "text": "The following example moves all data at the path  /data/SampleJSON  to  /data/SampleJSON2 .", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_7", 
            "text": "MOVE http://localhost:20223/data/fs/data/SampleJSON\n\nHeaders:\n  Destination: /data/SampleJSON2", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_9", 
            "text": "Status code 200 if successful. No response body.", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#retrieving-a-mount", 
            "text": "Retrieves the configuration for the mount point at the specified path.", 
            "title": "Retrieving a Mount"
        }, 
        {
            "location": "/api-reference/#url_8", 
            "text": "/mount/fs/{path}/  where  {path}  is a path for the mount to retrieve.  Note:  Be sure to end with a slash.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_8", 
            "text": "GET", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#example_8", 
            "text": "The following example returns mount at the path  / .", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_8", 
            "text": "GET http://localhost:20223/mount/fs/", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_10", 
            "text": "{\n   mongodb :\n  {\n     connectionUri : mongodb://myusername:mypassword@myserver.example.com:20223/data \n  }\n}", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#deleting-a-mount", 
            "text": "Deletes the MongoDB mount point at the specified path.  If there is no mount at the specified path, the request succeeds, but with no response.", 
            "title": "Deleting a Mount"
        }, 
        {
            "location": "/api-reference/#url_9", 
            "text": "/mount/fs/{path}/  where  {path}  is a path for the mount to delete.  Note:   Be sure to end with a slash.", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_9", 
            "text": "DELETE", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#response_11", 
            "text": "Returns the text \" deleted {path} \", where  {path}  is the path to the deleted mount.", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#example_9", 
            "text": "The following example deletes mount at the path  / .", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_9", 
            "text": "DELETE http://localhost:20223/mount/fs/", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_12", 
            "text": "deleted /", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#changing-the-port", 
            "text": "Shuts down the running instance and restarts the server on the specified port.  The port is specified in the PUT body.", 
            "title": "Changing the Port"
        }, 
        {
            "location": "/api-reference/#url_10", 
            "text": "/server/port", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_10", 
            "text": "PUT", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#response_13", 
            "text": "Returns the text \" changed port to {port-number} \", where  {port-number}  is the new port number.", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#example_10", 
            "text": "The following example changes the port number from 20223 to 20224.", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_10", 
            "text": "PUT http://localhost:20223/server/port\n\nPUT body:\n  20224", 
            "title": "Request"
        }, 
        {
            "location": "/api-reference/#response_14", 
            "text": "changed port to 20224", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#setting-the-port-to-the-default-value", 
            "text": "Shuts down the running instance and restarts the server on the default port, which is 20223.", 
            "title": "Setting the Port to the Default Value"
        }, 
        {
            "location": "/api-reference/#url_11", 
            "text": "/server/port", 
            "title": "URL"
        }, 
        {
            "location": "/api-reference/#method_11", 
            "text": "DELETE", 
            "title": "Method"
        }, 
        {
            "location": "/api-reference/#response_15", 
            "text": "None", 
            "title": "Response"
        }, 
        {
            "location": "/api-reference/#example_11", 
            "text": "The following example sets the port number from 20224 back to the default.", 
            "title": "Example"
        }, 
        {
            "location": "/api-reference/#request_11", 
            "text": "DELETE http://localhost:20224/server/port", 
            "title": "Request"
        }
    ]
}